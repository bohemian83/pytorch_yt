{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Pytorch Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 0. Computer vision libraries in PyTorch \n",
    "\n",
    "* `torchvision` - base domain library for PyTorch computer vision\n",
    "* `torchvision.datasets` - get datasets and data loading functions for CV\n",
    "* `torchvision.models` - get pretrained computer vision models\n",
    "* `torchvision.transforms` - functions for manipulation vision data for use in an ML model\n",
    "* `torch.utils.data.Dataset` - Base dataset class for PyTorch\n",
    "* `torch.utils.data.DataLoader` - Creates a Python iterable over a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "0.20.1\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision \n",
    "from torchvision import datasets \n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Other imports\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Check version\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting a dataset\n",
    "\n",
    "We will be using FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\", #save here\n",
    "    train=True, #get the training dataset\n",
    "    download=True, #download it\n",
    "    transform=torchvision.transforms.ToTensor(), #transform dataset with this method\n",
    "    target_transform=None #no transform for the target labels\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Check dimensions of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28]) -> [color channels, height, width]\n",
      "Image label: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "class_names = train_data.classes\n",
    "\n",
    "print(f\"Image shape: {image.shape} -> [color channels, height, width]\")\n",
    "print(f\"Image label: {class_names[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Visualizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(image.view(28, 28), cmap=\"grey\") # works too, but squeeze is better\n",
    "plt.imshow(image.squeeze(), cmap=\"grey\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot more images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"grey\")\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare DataLoader\n",
    "\n",
    "Right now our data are in the form of PyTorch tensors. A DataLoader turns our dataset into a Python iterables.\n",
    "\n",
    "We want to turn our data into batches (or mini-batches).\n",
    "\n",
    "Why?\n",
    "\n",
    "1. It is computationally more efficient, as our HW is most likely not able to store 60000 images in memory. So we break it down to 32 images at a time (batch size of 32).\n",
    "2. It gives out neural network more chances to updates its gradients per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x33356eea0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x33356fb30>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Train datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False)\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x33356eea0>, <torch.utils.data.dataloader.DataLoader object at 0x33356fb30>)\n",
      "Length of train dataloader: 1875 of 32.\n",
      "Length of test dataloader: 313 of 32.\n"
     ]
    }
   ],
   "source": [
    "# Let's check what we have created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} of {BATCH_SIZE}.\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} of {BATCH_SIZE}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out what is inside the dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 28, 28])\n",
      "Label: 6, label size: torch.Size([])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a saple\n",
    "torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size: {label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model 0: Build a baseline model\n",
    "\n",
    "Best practice in ML is to start with a base model, which you improve on with subsequent models/experiments. Start simple and introduce complexity as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before flattening: torch.Size([1, 28, 28])\n",
      "Shape before flattening: torch.Size([1, 784])\n"
     ]
    }
   ],
   "source": [
    "# Create a flatten layer\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "# Get a single sample\n",
    "x = train_features_batch[0]\n",
    "\n",
    "# Flatten the sample\n",
    "output = flatten_model(x)\n",
    "\n",
    "# Print out what is happening\n",
    "print(f\"Shape before flattening: {x.shape}\")\n",
    "print(f\"Shape before flattening: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModel0(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModel0(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Setup model with input parameters\n",
    "model_0 = FashionMNISTModel0(\n",
    "    input_shape=784,\n",
    "    hidden_units=10,\n",
    "    output_shape=len(class_names)\n",
    ").to(\"cpu\")\n",
    "\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0315,  0.3171,  0.0531, -0.2525,  0.5959,  0.2112,  0.3233,  0.2694,\n",
       "         -0.1004,  0.0157]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_x = torch.rand([1, 1, 28, 28])\n",
    "model_0(dummy_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Setup a loss function, optimizer and evaluation metrics\n",
    "\n",
    "* Loss function - since we are working with multiclass data our loss function will be `nn.CrossEntropyLess()`\n",
    "* Optimizer - our optimizer `torch.optim.SGD()`\n",
    "* Evaluation metric - since we are working on an classification problem, let's use accuracy as our metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_functions.py already exists, skipping download.\n"
     ]
    }
   ],
   "source": [
    "#Download helper function from Learn Pytorch repo\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "    print(\"helper_functions.py already exists, skipping download.\")\n",
    "else:\n",
    "    print(\"Downloading helper_functions.py\")\n",
    "    request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/refs/heads/main/helper_functions.py\")\n",
    "    with open(\"helper_functions.py\", \"wb\") as f:\n",
    "        f.write(request.content)\n",
    "    \n",
    "from helper_functions import plot_predictions, plot_decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import accuracy metric\n",
    "from helper_functions import accuracy_fn\n",
    "\n",
    "# Setup loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Creating a function to time our expertiments\n",
    "\n",
    "ML is very experimental.\n",
    "\n",
    "Two of the main things we often want to track:\n",
    "1. Model's performance (loss, accuracy etc)\n",
    "2. How fast model runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float,\n",
    "                     end: float, \n",
    "                     device: torch.device = None):\n",
    "    \"\"\"\n",
    "    Prints difference between start time and end time. \n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} in seconds.\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time on cpu: 0.000 in seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7875005141831934e-05"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = timer()\n",
    "# some code\n",
    "end_time = timer()\n",
    "print_train_time(start=start_time, end=end_time, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Creating a training loop and training on batches of data\n",
    "\n",
    "1. Loop through epochs\n",
    "2. Loop through training batches, perform training steps, calculate the train loss *per batch*\n",
    "3. Loop through testing batches, perform testing steps, calculate the test loss *per batch*\n",
    "4. Print out what's happening. \n",
    "5. Time it all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "------\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5904 | Test loss: 0.5095 | Test acc: 82.0387\n",
      "Epoch: 1\n",
      "------\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4763 | Test loss: 0.4799 | Test acc: 83.1969\n",
      "Epoch: 2\n",
      "------\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4550 | Test loss: 0.4766 | Test acc: 83.4265\n",
      "Train time on cpu: 3.860 in seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import tqdm for progress bar\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# Set the seed and start timer\n",
    "torch.manual_seed(42)\n",
    "train_time_on_cpu = timer()\n",
    "\n",
    "# Set the number of epochs. Low number for faster training time.\n",
    "epochs = 3\n",
    "\n",
    "# Create training and test loop\n",
    "for epoch in trange(epochs): #trange(x) same as tqdm(range(x))\n",
    "    print(f\"Epoch: {epoch}\\n------\")\n",
    "    ### Training\n",
    "    train_loss = 0\n",
    "    # Add a loop to loop through the training batches\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        # 1. Forward pass\n",
    "        y_pred = model_0(X)\n",
    "        # 2. Calculate loss (per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulate train loss\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        # 4. Backpropagation\n",
    "        loss.backward()\n",
    "        # 4. Optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print out what's happening\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
    "        \n",
    "    # Divide total train loss by length by length of train dataloader.\n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    ### Testing loop\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            # 1. Forward pass\n",
    "            test_pred = model_0(X_test)\n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "        \n",
    "        # Calculate the test loss and accuract average per batch\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "        \n",
    "    # Print out what is happening\n",
    "    print(f\"Train loss: {train_loss:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n",
    "    \n",
    "# Calculate training time\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_on_cpu,\n",
    "                                            end=train_time_end_on_cpu,\n",
    "                                            device=str(next(model_0.parameters()).device))           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make predictions and get Model_0 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn, \n",
    "               device=device):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader\"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(data_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Make predictions with the model\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            # Accumulate the loss and accuracy values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, \n",
    "                                y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
    "        \n",
    "        # Scale loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "        \n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 1871.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModel0',\n",
       " 'model_loss': 0.47663894295692444,\n",
       " 'model_acc': 83.42651757188499}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_0 results on test dataset\n",
    "model_0_results = eval_model(model=model_0,\n",
    "                             data_loader=test_dataloader, \n",
    "                             loss_fn=loss_fn, \n",
    "                             accuracy_fn=accuracy_fn,\n",
    "                             device=\"cpu\")\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 1: Building a better model with non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with linear and non-linear layers\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of model_1\n",
    "torch.manual_seed(42)\n",
    "model_1 = FashionMNISTModelV1(input_shape=784,\n",
    "                              hidden_units=10,\n",
    "                              output_shape=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Setup a loss function, optimizer and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Functionizing training and evaluation/testing loops\n",
    "\n",
    "Let's create a function for:\n",
    "* training loop - `train_step()`\n",
    "* testing loop - `test_step()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn, \n",
    "               device: torch.device = device):\n",
    "    \"\"\"Performs a training step with model trying to learn on data_loader\"\"\"\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Loop through the training batches\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        #Move data to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "        # 2. Calculate loss and accuracy (per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulate train loss\n",
    "        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        # 4. Backpropagation\n",
    "        loss.backward()\n",
    "        # 4. Optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print out what's happening\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(data_loader.dataset)} samples.\")\n",
    "        \n",
    "    # Divide total train loss and accuracy by length by length of train dataloader.\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    \n",
    "    # Print out what is happening\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn, \n",
    "               device: torch.device = device):\n",
    "    \"\"\"Performs a test step with model testing on data_loader\"\"\"\n",
    "    # Initialise loss and acc\n",
    "    test_loss, test_acc = 0, 0\n",
    "    # Put model on evaluation mode\n",
    "    model.eval()\n",
    "    # Use inference mode\n",
    "    with torch.inference_mode():\n",
    "        # Loop through the test batches\n",
    "        for X, y in test_dataloader:\n",
    "            #Move data to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
    "        \n",
    "        # Calculate the test loss and accuract average per batch\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "        \n",
    "    # Print out what is happening\n",
    "    print(f\"Test loss: {test_loss:.4f} | Test acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "------\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "Train loss: 1.09199 | Train acc: 61.34%\n",
      "Test loss: 0.9564 | Test acc: 65.00%\n",
      "Epoch: 1\n",
      "------\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "Train loss: 0.78097 | Train acc: 71.94%\n",
      "Test loss: 0.7261 | Test acc: 73.99%\n",
      "Epoch: 2\n",
      "------\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "Train loss: 0.67040 | Train acc: 75.94%\n",
      "Test loss: 0.6901 | Test acc: 74.81%\n",
      "Train time on mps:0: 11.600 in seconds.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "# Set epochs\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch}\\n------\")\n",
    "    ### Training\n",
    "    train_step(model=model_1,\n",
    "               data_loader=train_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               device=device\n",
    "               )\n",
    "    test_step(model=model_1,\n",
    "            data_loader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            accuracy_fn=accuracy_fn,\n",
    "            device=device\n",
    "            )\n",
    "    \n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                            end=train_time_end_on_gpu,\n",
    "                                            device=str(next(model_1.parameters()).device))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.600155749998521, 4.016846250000526)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_train_time_model_1, total_train_time_model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 793.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV1',\n",
       " 'model_loss': 0.6900655031204224,\n",
       " 'model_acc': 74.810303514377}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results = eval_model(model_1,\n",
    "                             data_loader=test_dataloader,\n",
    "                             loss_fn=loss_fn,\n",
    "                             accuracy_fn=accuracy_fn, \n",
    "                             device=device)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model 2: Building a Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convolutional neural network\n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units * 7 * 7, # 7 * 7 is the output shape of the second conv block\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_2 = FashionMNISTModelV2(input_shape=1, hidden_units=10, output_shape=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Stepping through `nn.Conv2d()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([32, 3, 64, 64])\n",
      "Single image shape: torch.Size([3, 64, 64])\n",
      "Test image:\n",
      " tensor([[[ 1.9269,  1.4873,  0.9007,  ...,  1.8446, -1.1845,  1.3835],\n",
      "         [ 1.4451,  0.8564,  2.2181,  ...,  0.3399,  0.7200,  0.4114],\n",
      "         [ 1.9312,  1.0119, -1.4364,  ..., -0.5558,  0.7043,  0.7099],\n",
      "         ...,\n",
      "         [-0.5610, -0.4830,  0.4770,  ..., -0.2713, -0.9537, -0.6737],\n",
      "         [ 0.3076, -0.1277,  0.0366,  ..., -2.0060,  0.2824, -0.8111],\n",
      "         [-1.5486,  0.0485, -0.7712,  ..., -0.1403,  0.9416, -0.0118]],\n",
      "\n",
      "        [[-0.5197,  1.8524,  1.8365,  ...,  0.8935, -1.5114, -0.8515],\n",
      "         [ 2.0818,  1.0677, -1.4277,  ...,  1.6612, -2.6223, -0.4319],\n",
      "         [-0.1010, -0.4388, -1.9775,  ...,  0.2106,  0.2536, -0.7318],\n",
      "         ...,\n",
      "         [ 0.2779,  0.7342, -0.3736,  ..., -0.4601,  0.1815,  0.1850],\n",
      "         [ 0.7205, -0.2833,  0.0937,  ..., -0.1002, -2.3609,  2.2465],\n",
      "         [-1.3242, -0.1973,  0.2920,  ...,  0.5409,  0.6940,  1.8563]],\n",
      "\n",
      "        [[-0.7978,  1.0261,  1.1465,  ...,  1.2134,  0.9354, -0.0780],\n",
      "         [-1.4647, -1.9571,  0.1017,  ..., -1.9986, -0.7409,  0.7011],\n",
      "         [-1.3938,  0.8466, -1.7191,  ..., -1.1867,  0.1320,  0.3407],\n",
      "         ...,\n",
      "         [ 0.8206, -0.3745,  1.2499,  ..., -0.0676,  0.0385,  0.6335],\n",
      "         [-0.5589, -0.3393,  0.2347,  ...,  2.1181,  2.4569,  1.3083],\n",
      "         [-0.4092,  1.5199,  0.2401,  ..., -0.2558,  0.7870,  0.9924]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a batch of images\n",
    "images = torch.randn(size=(32, 3, 64, 64))\n",
    "test_image = images[0]\n",
    "\n",
    "print(f\"Image batch shape: {images.shape}\")\n",
    "print(f\"Single image shape: {test_image.shape}\")\n",
    "print(f\"Test image:\\n {test_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_block_1.0.weight',\n",
       "              tensor([[[[ 0.2548,  0.2767, -0.0781],\n",
       "                        [ 0.3062, -0.0730,  0.0673],\n",
       "                        [-0.1623,  0.1958,  0.2938]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2445,  0.2897,  0.0624],\n",
       "                        [ 0.2463,  0.0451,  0.1607],\n",
       "                        [-0.0471,  0.2570,  0.0493]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1556,  0.0850, -0.1536],\n",
       "                        [-0.0391, -0.1354,  0.2211],\n",
       "                        [-0.2631, -0.1537, -0.0941]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2004,  0.0315, -0.3292],\n",
       "                        [ 0.3010, -0.2832,  0.2573],\n",
       "                        [ 0.0555, -0.1082,  0.2060]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0520,  0.2693,  0.0364],\n",
       "                        [-0.1051,  0.0896, -0.0904],\n",
       "                        [ 0.1403,  0.2976,  0.1927]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1457,  0.1924,  0.0596],\n",
       "                        [ 0.1693, -0.2032, -0.3300],\n",
       "                        [-0.1288, -0.2557,  0.2735]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0960,  0.1381,  0.1054],\n",
       "                        [-0.0058,  0.2609, -0.2368],\n",
       "                        [ 0.0210, -0.2275,  0.1028]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1148,  0.1021, -0.0694],\n",
       "                        [ 0.2765, -0.1976, -0.1988],\n",
       "                        [-0.1988,  0.2998,  0.1111]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3208, -0.2751, -0.3306],\n",
       "                        [-0.2608, -0.2242,  0.1350],\n",
       "                        [ 0.1194,  0.2770, -0.1721]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2272,  0.1769, -0.1347],\n",
       "                        [ 0.2023, -0.0791,  0.1907],\n",
       "                        [-0.2590, -0.1682,  0.1016]]]], device='mps:0')),\n",
       "             ('conv_block_1.0.bias',\n",
       "              tensor([ 0.0705, -0.0850,  0.1987,  0.2266, -0.2417, -0.1780,  0.3052, -0.1125,\n",
       "                      -0.1182, -0.3225], device='mps:0')),\n",
       "             ('conv_block_1.2.weight',\n",
       "              tensor([[[[-0.0604,  0.0263, -0.0139],\n",
       "                        [-0.0765,  0.0025, -0.0720],\n",
       "                        [-0.0894, -0.0580, -0.0923]],\n",
       "              \n",
       "                       [[-0.0671,  0.1054,  0.0199],\n",
       "                        [ 0.0325, -0.0983, -0.0692],\n",
       "                        [-0.0351,  0.0165, -0.0928]],\n",
       "              \n",
       "                       [[-0.0454, -0.0631,  0.0003],\n",
       "                        [-0.0392, -0.0073, -0.0714],\n",
       "                        [-0.0724, -0.0615, -0.0361]],\n",
       "              \n",
       "                       [[-0.0832,  0.0884, -0.0209],\n",
       "                        [ 0.0907,  0.0328, -0.0893],\n",
       "                        [ 0.0729, -0.0290, -0.0404]],\n",
       "              \n",
       "                       [[-0.0875, -0.1048,  0.0302],\n",
       "                        [-0.0230,  0.0410, -0.0865],\n",
       "                        [ 0.0783, -0.0774, -0.0182]],\n",
       "              \n",
       "                       [[ 0.0220,  0.0544,  0.0851],\n",
       "                        [ 0.0960, -0.0836,  0.0265],\n",
       "                        [-0.0453, -0.0116, -0.0789]],\n",
       "              \n",
       "                       [[ 0.0960, -0.0774,  0.0563],\n",
       "                        [ 0.0370,  0.0343, -0.0570],\n",
       "                        [ 0.0958,  0.0232,  0.0136]],\n",
       "              \n",
       "                       [[-0.0929,  0.0442, -0.0158],\n",
       "                        [-0.0483,  0.0905,  0.0235],\n",
       "                        [-0.0583, -0.0534, -0.0050]],\n",
       "              \n",
       "                       [[ 0.0589, -0.0269, -0.0601],\n",
       "                        [-0.0361, -0.0787,  0.0376],\n",
       "                        [ 0.0816, -0.0992,  0.0245]],\n",
       "              \n",
       "                       [[ 0.0545,  0.0191, -0.0375],\n",
       "                        [ 0.0550,  0.0554,  0.0394],\n",
       "                        [-0.0185, -0.0279,  0.0113]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0186, -0.0314,  0.0674],\n",
       "                        [ 0.0906, -0.0104, -0.0236],\n",
       "                        [ 0.0015, -0.0063,  0.0253]],\n",
       "              \n",
       "                       [[ 0.0295, -0.0957, -0.0389],\n",
       "                        [ 0.0888,  0.0411, -0.0052],\n",
       "                        [-0.0636, -0.0645, -0.0944]],\n",
       "              \n",
       "                       [[-0.0344,  0.0356,  0.0672],\n",
       "                        [ 0.0487, -0.0932, -0.0634],\n",
       "                        [-0.0166,  0.1020,  0.0152]],\n",
       "              \n",
       "                       [[-0.0273,  0.0436, -0.0401],\n",
       "                        [-0.0682,  0.0769, -0.0479],\n",
       "                        [-0.0211, -0.1049,  0.0705]],\n",
       "              \n",
       "                       [[ 0.0799,  0.0384, -0.0735],\n",
       "                        [-0.1040, -0.0856,  0.0786],\n",
       "                        [ 0.0506,  0.0887,  0.0552]],\n",
       "              \n",
       "                       [[ 0.0267, -0.0010, -0.0802],\n",
       "                        [-0.0903, -0.0986,  0.0432],\n",
       "                        [-0.0518, -0.0212, -0.0607]],\n",
       "              \n",
       "                       [[-0.0192, -0.0742, -0.0689],\n",
       "                        [ 0.0350, -0.0313,  0.0651],\n",
       "                        [-0.0338, -0.0773, -0.0186]],\n",
       "              \n",
       "                       [[-0.0511, -0.0322, -0.1003],\n",
       "                        [ 0.0590, -0.0734,  0.0530],\n",
       "                        [ 0.0478,  0.0753, -0.0809]],\n",
       "              \n",
       "                       [[ 0.0758, -0.0498,  0.0391],\n",
       "                        [ 0.0990, -0.0149, -0.0008],\n",
       "                        [-0.0243, -0.0880,  0.0506]],\n",
       "              \n",
       "                       [[-0.1046,  0.0654,  0.0789],\n",
       "                        [ 0.0997, -0.0249, -0.0866],\n",
       "                        [ 0.0237,  0.0582, -0.1049]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0239, -0.0632, -0.0092],\n",
       "                        [-0.0519, -0.0431, -0.0335],\n",
       "                        [-0.1002,  0.0865,  0.0884]],\n",
       "              \n",
       "                       [[-0.0165, -0.0120, -0.0430],\n",
       "                        [-0.0952, -0.1026,  0.0392],\n",
       "                        [-0.0579, -0.0678, -0.0082]],\n",
       "              \n",
       "                       [[-0.0351, -0.0341,  0.0034],\n",
       "                        [-0.0224, -0.0363, -0.0505],\n",
       "                        [-0.0858,  0.0884, -0.0422]],\n",
       "              \n",
       "                       [[ 0.0279, -0.0366,  0.0086],\n",
       "                        [ 0.0983,  0.0486, -0.0913],\n",
       "                        [ 0.0418,  0.1001,  0.0277]],\n",
       "              \n",
       "                       [[ 0.0707,  0.1039, -0.0162],\n",
       "                        [ 0.0219, -0.0733, -0.0217],\n",
       "                        [ 0.0781,  0.0540, -0.0667]],\n",
       "              \n",
       "                       [[-0.0845, -0.0720, -0.1040],\n",
       "                        [-0.0813, -0.0261,  0.0711],\n",
       "                        [ 0.0176, -0.0802, -0.0846]],\n",
       "              \n",
       "                       [[ 0.0524, -0.0784, -0.0130],\n",
       "                        [ 0.0506, -0.0488, -0.0115],\n",
       "                        [-0.0092, -0.0249, -0.0534]],\n",
       "              \n",
       "                       [[-0.0940, -0.0852, -0.0564],\n",
       "                        [ 0.1018, -0.0509, -0.0708],\n",
       "                        [ 0.0256,  0.0291,  0.0578]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0587, -0.1045],\n",
       "                        [ 0.0093,  0.0639, -0.0097],\n",
       "                        [-0.0621,  0.1005, -0.0394]],\n",
       "              \n",
       "                       [[-0.0600, -0.0950,  0.0047],\n",
       "                        [ 0.0467,  0.0233,  0.0208],\n",
       "                        [-0.0799, -0.0984,  0.0019]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0961,  0.0608, -0.0614],\n",
       "                        [-0.0137, -0.0777, -0.0509],\n",
       "                        [ 0.0191,  0.0574,  0.0873]],\n",
       "              \n",
       "                       [[-0.0968,  0.0705, -0.0743],\n",
       "                        [ 0.0395,  0.0892,  0.0015],\n",
       "                        [ 0.0959, -0.0898, -0.0403]],\n",
       "              \n",
       "                       [[ 0.0615, -0.0230, -0.0216],\n",
       "                        [-0.0439,  0.0727,  0.0517],\n",
       "                        [ 0.0338, -0.0592, -0.0856]],\n",
       "              \n",
       "                       [[ 0.0114,  0.0312, -0.0487],\n",
       "                        [-0.0295,  0.0712,  0.0084],\n",
       "                        [ 0.0048, -0.0259, -0.0955]],\n",
       "              \n",
       "                       [[-0.0991, -0.0504, -0.0536],\n",
       "                        [ 0.0328, -0.0307, -0.0412],\n",
       "                        [ 0.1005,  0.0367,  0.0751]],\n",
       "              \n",
       "                       [[-0.0510, -0.0431,  0.0387],\n",
       "                        [-0.0702, -0.0689, -0.0051],\n",
       "                        [-0.0386, -0.0790,  0.0625]],\n",
       "              \n",
       "                       [[ 0.0848,  0.0171, -0.0184],\n",
       "                        [-0.0976, -0.0384,  0.0268],\n",
       "                        [ 0.0497, -0.0133, -0.0417]],\n",
       "              \n",
       "                       [[ 0.0587, -0.0839,  0.0666],\n",
       "                        [-0.0409,  0.0016, -0.0208],\n",
       "                        [ 0.0128, -0.0319,  0.0766]],\n",
       "              \n",
       "                       [[-0.0027,  0.0823,  0.1013],\n",
       "                        [-0.0514, -0.0769,  0.0846],\n",
       "                        [ 0.0826, -0.0805, -0.0081]],\n",
       "              \n",
       "                       [[-0.1039, -0.0863,  0.0204],\n",
       "                        [ 0.0280,  0.0223, -0.0287],\n",
       "                        [ 0.0972,  0.0151, -0.0622]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0060,  0.0253,  0.0369],\n",
       "                        [-0.0745,  0.0395, -0.0539],\n",
       "                        [-0.0876, -0.0576,  0.1017]],\n",
       "              \n",
       "                       [[ 0.0901,  0.0944,  0.0619],\n",
       "                        [ 0.0796, -0.0141, -0.0580],\n",
       "                        [ 0.0527, -0.0546, -0.0711]],\n",
       "              \n",
       "                       [[-0.0337,  0.0221,  0.0543],\n",
       "                        [-0.0409, -0.0620,  0.0142],\n",
       "                        [-0.0621, -0.0686,  0.0549]],\n",
       "              \n",
       "                       [[-0.0177,  0.0963,  0.1025],\n",
       "                        [ 0.0315,  0.0363,  0.0243],\n",
       "                        [ 0.0017, -0.0077,  0.0014]],\n",
       "              \n",
       "                       [[ 0.0394,  0.0980, -0.0273],\n",
       "                        [-0.0446, -0.0255, -0.0509],\n",
       "                        [ 0.0179,  0.0787,  0.0824]],\n",
       "              \n",
       "                       [[ 0.0484, -0.0776, -0.0566],\n",
       "                        [-0.0232, -0.0194,  0.0087],\n",
       "                        [-0.0968,  0.0328, -0.0804]],\n",
       "              \n",
       "                       [[-0.0667, -0.0876,  0.0918],\n",
       "                        [-0.0998,  0.0795, -0.0035],\n",
       "                        [-0.0123,  0.0659, -0.0097]],\n",
       "              \n",
       "                       [[ 0.0661,  0.0762, -0.0915],\n",
       "                        [ 0.0406,  0.0199,  0.0227],\n",
       "                        [ 0.0154,  0.0288, -0.0507]],\n",
       "              \n",
       "                       [[-0.0135,  0.1002,  0.0708],\n",
       "                        [-0.0040, -0.0991,  0.0046],\n",
       "                        [-0.0718,  0.0857, -0.0640]],\n",
       "              \n",
       "                       [[-0.0076, -0.0234,  0.0188],\n",
       "                        [ 0.0992,  0.0100,  0.0610],\n",
       "                        [ 0.0818,  0.0851, -0.0364]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0236,  0.0508, -0.0288],\n",
       "                        [ 0.0494, -0.0230, -0.0715],\n",
       "                        [ 0.0429,  0.0162,  0.0470]],\n",
       "              \n",
       "                       [[ 0.1047,  0.0720,  0.0999],\n",
       "                        [ 0.0056, -0.0907, -0.0739],\n",
       "                        [-0.0655, -0.0929, -0.0528]],\n",
       "              \n",
       "                       [[-0.0970, -0.0973, -0.0630],\n",
       "                        [-0.1039, -0.0647,  0.0402],\n",
       "                        [ 0.0879, -0.0314, -0.0307]],\n",
       "              \n",
       "                       [[ 0.0563, -0.0520, -0.0498],\n",
       "                        [ 0.0649, -0.0918,  0.0129],\n",
       "                        [ 0.0931,  0.0181,  0.0287]],\n",
       "              \n",
       "                       [[-0.0614, -0.0015,  0.0058],\n",
       "                        [ 0.0259,  0.0410,  0.0916],\n",
       "                        [-0.0805,  0.0032, -0.0527]],\n",
       "              \n",
       "                       [[-0.0834, -0.0084, -0.0928],\n",
       "                        [ 0.0736,  0.0122, -0.0568],\n",
       "                        [ 0.0551, -0.0998, -0.0408]],\n",
       "              \n",
       "                       [[-0.0205, -0.0896, -0.0670],\n",
       "                        [-0.0172,  0.0800,  0.1018],\n",
       "                        [ 0.0671, -0.0629, -0.0690]],\n",
       "              \n",
       "                       [[ 0.0920,  0.0373,  0.0028],\n",
       "                        [ 0.0143, -0.0847, -0.0352],\n",
       "                        [ 0.1015, -0.0260, -0.0053]],\n",
       "              \n",
       "                       [[-0.0875, -0.0590, -0.0022],\n",
       "                        [-0.0655, -0.0131,  0.0429],\n",
       "                        [-0.1031,  0.0313, -0.0697]],\n",
       "              \n",
       "                       [[-0.0514,  0.0405,  0.0838],\n",
       "                        [-0.0288, -0.0433, -0.0953],\n",
       "                        [-0.0544, -0.0923, -0.0241]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0215, -0.0988,  0.0920],\n",
       "                        [ 0.0661, -0.1032, -0.0503],\n",
       "                        [ 0.0344, -0.0217, -0.0115]],\n",
       "              \n",
       "                       [[-0.0476,  0.0847, -0.0589],\n",
       "                        [ 0.0874,  0.0068,  0.0212],\n",
       "                        [ 0.0822, -0.0174, -0.0600]],\n",
       "              \n",
       "                       [[-0.0170,  0.0855, -0.0782],\n",
       "                        [ 0.0239, -0.1036,  0.0553],\n",
       "                        [ 0.0389,  0.0045,  0.0452]],\n",
       "              \n",
       "                       [[ 0.0001,  0.0583, -0.0834],\n",
       "                        [-0.0155,  0.0468,  0.1050],\n",
       "                        [ 0.0537, -0.0767,  0.0811]],\n",
       "              \n",
       "                       [[-0.0235, -0.0225, -0.0958],\n",
       "                        [-0.0166,  0.0746,  0.0147],\n",
       "                        [-0.0614,  0.0324, -0.0338]],\n",
       "              \n",
       "                       [[ 0.0962, -0.0915, -0.0333],\n",
       "                        [-0.1018, -0.0415,  0.0332],\n",
       "                        [ 0.1015,  0.0177,  0.1033]],\n",
       "              \n",
       "                       [[ 0.0206,  0.0609,  0.0845],\n",
       "                        [ 0.0881, -0.0590,  0.0969],\n",
       "                        [ 0.0639, -0.0493, -0.0503]],\n",
       "              \n",
       "                       [[-0.0884,  0.0265, -0.0854],\n",
       "                        [ 0.0445,  0.0333, -0.0916],\n",
       "                        [ 0.0287, -0.0086,  0.0482]],\n",
       "              \n",
       "                       [[ 0.0605, -0.1048,  0.0967],\n",
       "                        [ 0.0884,  0.0419, -0.0963],\n",
       "                        [-0.0377, -0.0305, -0.0271]],\n",
       "              \n",
       "                       [[ 0.0594,  0.0383,  0.0835],\n",
       "                        [-0.0395,  0.0355,  0.0375],\n",
       "                        [-0.0878, -0.1022, -0.0547]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0722, -0.0992, -0.0918],\n",
       "                        [ 0.0591,  0.0569,  0.0867],\n",
       "                        [-0.0796, -0.0771,  0.0541]],\n",
       "              \n",
       "                       [[ 0.0917,  0.0631,  0.0165],\n",
       "                        [ 0.0347,  0.1000, -0.0680],\n",
       "                        [-0.0479,  0.0737, -0.0721]],\n",
       "              \n",
       "                       [[-0.0581,  0.0769,  0.0333],\n",
       "                        [ 0.0341, -0.0447, -0.0015],\n",
       "                        [ 0.0965, -0.0633,  0.0008]],\n",
       "              \n",
       "                       [[ 0.0501, -0.0728,  0.1024],\n",
       "                        [-0.0527, -0.0253, -0.0285],\n",
       "                        [-0.0687, -0.1034,  0.0594]],\n",
       "              \n",
       "                       [[ 0.0280, -0.0987, -0.0678],\n",
       "                        [ 0.1042,  0.0403,  0.0423],\n",
       "                        [-0.0631, -0.0462, -0.0159]],\n",
       "              \n",
       "                       [[-0.0193, -0.0722,  0.0087],\n",
       "                        [ 0.0105, -0.0133,  0.0146],\n",
       "                        [-0.0418,  0.0274,  0.0398]],\n",
       "              \n",
       "                       [[-0.0555, -0.1045,  0.0552],\n",
       "                        [ 0.0251, -0.0536,  0.1016],\n",
       "                        [-0.0477,  0.0712,  0.0535]],\n",
       "              \n",
       "                       [[-0.0884,  0.0680, -0.0969],\n",
       "                        [-0.0584, -0.0176, -0.0711],\n",
       "                        [ 0.1030, -0.0211,  0.0419]],\n",
       "              \n",
       "                       [[-0.0941,  0.0607, -0.0328],\n",
       "                        [-0.0802,  0.0154,  0.0511],\n",
       "                        [ 0.0912, -0.0644, -0.0519]],\n",
       "              \n",
       "                       [[ 0.0203,  0.0286,  0.0405],\n",
       "                        [ 0.0579, -0.0239,  0.0586],\n",
       "                        [ 0.0777, -0.0275,  0.0750]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0515,  0.0930, -0.0599],\n",
       "                        [-0.0521, -0.0305,  0.0053],\n",
       "                        [ 0.0633, -0.0602,  0.0528]],\n",
       "              \n",
       "                       [[-0.0378,  0.0637, -0.0050],\n",
       "                        [-0.0923, -0.0580, -0.0763],\n",
       "                        [ 0.0523, -0.0707, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0227, -0.0578,  0.0304],\n",
       "                        [-0.1029, -0.0754, -0.0955],\n",
       "                        [-0.0319, -0.0384,  0.0151]],\n",
       "              \n",
       "                       [[-0.0195,  0.0496,  0.0966],\n",
       "                        [ 0.0378, -0.0415, -0.0987],\n",
       "                        [ 0.0382, -0.0522,  0.0536]],\n",
       "              \n",
       "                       [[ 0.0705,  0.0407,  0.0989],\n",
       "                        [ 0.1001,  0.0223, -0.0768],\n",
       "                        [ 0.0942, -0.0500, -0.0498]],\n",
       "              \n",
       "                       [[ 0.0882,  0.0817,  0.0318],\n",
       "                        [ 0.0066, -0.0887, -0.0109],\n",
       "                        [ 0.1011,  0.0268,  0.0090]],\n",
       "              \n",
       "                       [[-0.0219, -0.0368,  0.0628],\n",
       "                        [ 0.0065,  0.0686, -0.0187],\n",
       "                        [ 0.0461,  0.0435,  0.0168]],\n",
       "              \n",
       "                       [[ 0.0662,  0.0661,  0.0977],\n",
       "                        [ 0.0810, -0.0270, -0.0892],\n",
       "                        [ 0.0193, -0.0009, -0.0275]],\n",
       "              \n",
       "                       [[-0.0177,  0.0050,  0.0769],\n",
       "                        [ 0.0329, -0.0374, -0.0433],\n",
       "                        [-0.0261, -0.0407,  0.0948]],\n",
       "              \n",
       "                       [[ 0.0558,  0.0952,  0.0003],\n",
       "                        [ 0.0213,  0.0366, -0.0998],\n",
       "                        [ 0.0094, -0.0071, -0.0591]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0818,  0.0933,  0.0857],\n",
       "                        [ 0.0489,  0.1006, -0.0428],\n",
       "                        [-0.0182,  0.0399, -0.0174]],\n",
       "              \n",
       "                       [[-0.0207, -0.0871,  0.0283],\n",
       "                        [-0.0637,  0.0038,  0.1028],\n",
       "                        [-0.0324, -0.0332,  0.0636]],\n",
       "              \n",
       "                       [[-0.0388, -0.0091,  0.0984],\n",
       "                        [-0.0432, -0.0754, -0.0590],\n",
       "                        [-0.0292, -0.0500, -0.0547]],\n",
       "              \n",
       "                       [[ 0.0426,  0.0179, -0.0337],\n",
       "                        [-0.0819, -0.0332, -0.0445],\n",
       "                        [-0.0343, -0.0951,  0.0227]],\n",
       "              \n",
       "                       [[-0.0774, -0.0821, -0.0861],\n",
       "                        [ 0.0440, -0.0635, -0.0435],\n",
       "                        [ 0.0826,  0.0560,  0.0604]],\n",
       "              \n",
       "                       [[-0.1001, -0.0756, -0.0398],\n",
       "                        [ 0.0871,  0.0108, -0.0788],\n",
       "                        [ 0.0007, -0.0819, -0.0231]],\n",
       "              \n",
       "                       [[-0.0290,  0.0912,  0.0326],\n",
       "                        [-0.0184,  0.0178, -0.0304],\n",
       "                        [ 0.0414,  0.0417,  0.0283]],\n",
       "              \n",
       "                       [[-0.0411,  0.0899, -0.0152],\n",
       "                        [-0.0410,  0.0660,  0.0859],\n",
       "                        [ 0.1049,  0.0312, -0.0359]],\n",
       "              \n",
       "                       [[ 0.0535,  0.0904, -0.1034],\n",
       "                        [-0.0131, -0.0719,  0.0196],\n",
       "                        [ 0.0436, -0.0218, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0474, -0.0177, -0.0885],\n",
       "                        [ 0.0843, -0.0531, -0.0116],\n",
       "                        [ 0.0099, -0.0063, -0.0992]]]], device='mps:0')),\n",
       "             ('conv_block_1.2.bias',\n",
       "              tensor([ 0.0484, -0.0479, -0.0547,  0.0252, -0.0550, -0.0487, -0.0355, -0.0396,\n",
       "                      -0.0440, -0.0284], device='mps:0')),\n",
       "             ('conv_block_2.0.weight',\n",
       "              tensor([[[[ 2.7393e-02, -8.5299e-02, -6.3802e-02],\n",
       "                        [ 1.5381e-03,  1.4659e-02,  5.8217e-02],\n",
       "                        [-7.4044e-02,  3.3646e-02,  5.9914e-02]],\n",
       "              \n",
       "                       [[ 5.8530e-02, -9.8180e-02, -4.0225e-02],\n",
       "                        [-9.0606e-02, -6.6704e-02,  5.8711e-02],\n",
       "                        [-1.5740e-02,  4.4769e-02, -6.1876e-02]],\n",
       "              \n",
       "                       [[ 1.6018e-02, -6.3758e-02,  5.2693e-02],\n",
       "                        [-4.6104e-02, -2.6432e-02, -9.1456e-02],\n",
       "                        [ 3.4822e-04,  1.0008e-01,  5.1163e-02]],\n",
       "              \n",
       "                       [[-5.6240e-02,  1.4176e-03, -1.1558e-02],\n",
       "                        [-8.4862e-02,  8.2650e-02,  1.6993e-03],\n",
       "                        [ 2.2199e-02, -4.2567e-02, -4.9323e-02]],\n",
       "              \n",
       "                       [[ 1.7381e-02,  3.8971e-02,  2.3643e-02],\n",
       "                        [-5.0801e-02,  1.0234e-01, -1.5517e-02],\n",
       "                        [-6.4554e-02, -4.9301e-02,  1.0377e-01]],\n",
       "              \n",
       "                       [[ 5.0766e-06, -1.4309e-02, -4.3867e-02],\n",
       "                        [-2.7633e-02, -8.8779e-02, -8.3767e-02],\n",
       "                        [ 6.1695e-02,  9.0172e-02,  1.0059e-01]],\n",
       "              \n",
       "                       [[-7.6099e-02,  5.7012e-02, -6.5245e-02],\n",
       "                        [ 6.2883e-02,  7.6058e-02,  8.1573e-02],\n",
       "                        [ 7.5900e-02,  6.5941e-02,  2.0516e-03]],\n",
       "              \n",
       "                       [[ 4.8434e-02, -3.7712e-02,  4.5899e-02],\n",
       "                        [-3.3879e-02, -1.7700e-03, -9.1746e-02],\n",
       "                        [-2.7562e-02, -5.5432e-02, -3.5557e-02]],\n",
       "              \n",
       "                       [[-6.7313e-02, -9.4810e-02,  6.8639e-03],\n",
       "                        [ 6.8408e-02,  9.6001e-02,  6.1512e-02],\n",
       "                        [-5.4638e-02, -1.0425e-01,  3.9983e-02]],\n",
       "              \n",
       "                       [[ 5.9062e-02, -9.0495e-02,  3.7798e-02],\n",
       "                        [ 8.9121e-02,  6.3853e-03, -6.3505e-02],\n",
       "                        [ 8.6423e-02,  4.5011e-02,  6.9802e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.1287e-02,  6.1342e-02, -7.2002e-02],\n",
       "                        [ 1.0430e-01, -4.4662e-02,  6.3516e-02],\n",
       "                        [ 2.1107e-02,  2.7935e-02, -1.6165e-02]],\n",
       "              \n",
       "                       [[ 4.3295e-02, -4.3932e-02, -9.9357e-02],\n",
       "                        [-4.0499e-02,  8.2592e-02, -2.7751e-02],\n",
       "                        [ 3.3132e-02, -3.8973e-02,  7.9073e-02]],\n",
       "              \n",
       "                       [[ 6.3086e-02,  3.7211e-02, -5.3881e-02],\n",
       "                        [-8.6133e-02,  3.9686e-03, -6.1839e-02],\n",
       "                        [ 8.6667e-02, -1.0130e-01,  4.7104e-02]],\n",
       "              \n",
       "                       [[ 1.0508e-01,  5.2792e-02,  3.5942e-02],\n",
       "                        [-1.0142e-01,  1.0139e-01, -1.8030e-02],\n",
       "                        [-9.8495e-02,  1.0406e-01, -4.2894e-02]],\n",
       "              \n",
       "                       [[-7.4575e-03,  9.6479e-02, -7.3070e-02],\n",
       "                        [-7.4576e-02,  1.7141e-02, -1.4109e-02],\n",
       "                        [ 2.4280e-02, -8.8407e-02,  3.1524e-03]],\n",
       "              \n",
       "                       [[-4.6882e-02, -5.1820e-02, -9.6517e-02],\n",
       "                        [ 5.5890e-02,  2.0306e-02, -8.9118e-02],\n",
       "                        [ 8.3648e-02,  3.1794e-02,  1.9560e-02]],\n",
       "              \n",
       "                       [[-6.1890e-02,  1.5896e-02,  1.0157e-01],\n",
       "                        [ 7.2299e-02, -8.2100e-02,  9.6220e-02],\n",
       "                        [ 8.1702e-03,  5.0698e-02,  8.1869e-02]],\n",
       "              \n",
       "                       [[ 8.9862e-02, -8.2170e-02,  9.2303e-02],\n",
       "                        [-7.1591e-02,  7.9021e-03, -7.3656e-02],\n",
       "                        [-2.3109e-02, -4.7901e-03, -1.2611e-02]],\n",
       "              \n",
       "                       [[-1.6652e-02,  8.3137e-03,  1.0398e-01],\n",
       "                        [ 6.1244e-02,  5.8973e-02,  4.2190e-02],\n",
       "                        [ 8.1606e-02, -4.8645e-03,  8.3813e-03]],\n",
       "              \n",
       "                       [[ 2.1693e-02, -9.1931e-02, -8.4913e-02],\n",
       "                        [ 1.2923e-02, -4.1241e-02, -1.9342e-03],\n",
       "                        [-2.4187e-02,  1.6408e-02,  6.8581e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4958e-02,  8.4418e-02,  8.3227e-02],\n",
       "                        [-8.0901e-02, -8.1400e-02, -8.5284e-02],\n",
       "                        [-5.7766e-02, -4.1033e-02, -7.9341e-03]],\n",
       "              \n",
       "                       [[-2.5635e-02, -5.3258e-02, -3.3488e-02],\n",
       "                        [-3.8131e-02,  1.0341e-01, -3.9068e-02],\n",
       "                        [-7.5473e-02,  4.3818e-02, -6.0886e-03]],\n",
       "              \n",
       "                       [[ 8.0698e-02,  6.5863e-02,  9.6843e-02],\n",
       "                        [-7.7197e-02,  6.7764e-02,  8.8464e-02],\n",
       "                        [-5.2054e-02,  9.6890e-02,  7.9019e-02]],\n",
       "              \n",
       "                       [[ 1.1544e-03,  5.0823e-02, -3.6853e-02],\n",
       "                        [-9.1936e-02,  2.6645e-02,  3.1425e-02],\n",
       "                        [-6.8891e-02,  5.1123e-02, -9.0043e-02]],\n",
       "              \n",
       "                       [[ 9.0718e-02,  1.0208e-01,  2.8699e-02],\n",
       "                        [-6.6137e-02,  5.1300e-02,  1.7963e-02],\n",
       "                        [ 2.8663e-02,  3.4643e-02,  8.0254e-02]],\n",
       "              \n",
       "                       [[-4.5309e-02, -2.3711e-02,  2.8746e-02],\n",
       "                        [ 1.1486e-02,  8.5000e-02, -5.5365e-02],\n",
       "                        [-3.8387e-03,  1.9696e-02, -2.7996e-02]],\n",
       "              \n",
       "                       [[ 7.1859e-02,  1.1530e-02, -9.7422e-02],\n",
       "                        [-1.1420e-02, -4.7809e-02,  1.0243e-02],\n",
       "                        [-1.2250e-02, -1.0456e-01, -1.9208e-02]],\n",
       "              \n",
       "                       [[-1.0096e-02, -3.1083e-02,  9.6848e-02],\n",
       "                        [-2.3000e-02,  6.7717e-02,  2.6112e-02],\n",
       "                        [-8.8979e-02,  2.4770e-02,  8.7356e-02]],\n",
       "              \n",
       "                       [[-6.8948e-02, -6.8134e-02,  1.0318e-01],\n",
       "                        [ 8.4697e-02, -5.8807e-02,  6.3429e-02],\n",
       "                        [-1.3485e-02, -1.0393e-01,  7.9198e-03]],\n",
       "              \n",
       "                       [[ 3.4057e-02, -3.1619e-02,  3.6670e-02],\n",
       "                        [-9.0136e-02,  7.3050e-02,  8.9865e-02],\n",
       "                        [ 5.8130e-02,  1.7866e-02,  3.4716e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.6269e-02, -2.6339e-02, -1.0063e-02],\n",
       "                        [-5.8659e-02, -7.7857e-02,  7.0900e-02],\n",
       "                        [ 7.1535e-02, -9.5731e-02,  3.3542e-02]],\n",
       "              \n",
       "                       [[ 4.2881e-02,  1.0014e-01,  6.0985e-02],\n",
       "                        [ 9.6907e-02, -3.4510e-02,  7.3827e-02],\n",
       "                        [ 8.5740e-02, -9.9541e-02, -8.4613e-02]],\n",
       "              \n",
       "                       [[ 2.1335e-02,  5.7557e-02, -5.2369e-02],\n",
       "                        [ 1.1609e-02, -1.5303e-04,  2.6680e-02],\n",
       "                        [-5.6642e-02,  5.9455e-02,  7.0098e-02]],\n",
       "              \n",
       "                       [[-7.3139e-02,  1.0211e-03,  2.9247e-04],\n",
       "                        [ 3.3849e-02,  9.8198e-02,  3.0913e-02],\n",
       "                        [-2.3951e-02,  9.4672e-02, -4.0112e-02]],\n",
       "              \n",
       "                       [[-3.0608e-02,  7.1969e-03, -8.0270e-02],\n",
       "                        [ 1.1470e-02, -7.1518e-02,  1.0838e-02],\n",
       "                        [ 1.0099e-02,  1.4591e-02, -8.8891e-02]],\n",
       "              \n",
       "                       [[-1.0012e-01,  4.8501e-02,  9.0399e-02],\n",
       "                        [-9.3537e-02,  3.9043e-02, -7.7594e-02],\n",
       "                        [ 6.6082e-03,  9.8068e-02,  7.9965e-02]],\n",
       "              \n",
       "                       [[-7.7069e-02,  6.5203e-02,  5.5057e-02],\n",
       "                        [-1.6168e-04,  1.0211e-01, -4.1866e-02],\n",
       "                        [-2.4530e-02, -5.3275e-02,  1.5168e-02]],\n",
       "              \n",
       "                       [[ 2.7911e-02,  8.3990e-03, -5.9307e-02],\n",
       "                        [-4.7452e-02,  3.5855e-02, -9.2426e-02],\n",
       "                        [-1.6416e-02, -2.3350e-03, -4.2708e-02]],\n",
       "              \n",
       "                       [[ 3.8360e-02,  6.7940e-03,  7.4004e-02],\n",
       "                        [-9.3616e-03, -6.6528e-02,  7.4477e-02],\n",
       "                        [ 1.4720e-02, -3.0189e-02, -6.9476e-02]],\n",
       "              \n",
       "                       [[ 2.4707e-02, -1.0053e-01,  2.7762e-02],\n",
       "                        [ 5.2119e-02, -9.2465e-02, -6.9009e-02],\n",
       "                        [-7.5781e-02,  8.8597e-02,  8.9611e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.5987e-03,  9.8959e-02, -3.5239e-02],\n",
       "                        [-1.0233e-01,  3.6819e-02,  3.7343e-02],\n",
       "                        [ 1.0334e-01, -3.0510e-05,  8.0785e-02]],\n",
       "              \n",
       "                       [[ 6.4612e-02,  7.6292e-02, -1.0460e-01],\n",
       "                        [ 8.6800e-02, -8.9856e-02,  9.4501e-02],\n",
       "                        [-4.3682e-03, -9.3415e-02,  2.9314e-02]],\n",
       "              \n",
       "                       [[-2.1456e-02, -9.4678e-02, -3.8215e-02],\n",
       "                        [ 1.0868e-02,  8.2098e-02, -3.2406e-02],\n",
       "                        [ 6.2610e-02,  1.3200e-02,  3.5531e-03]],\n",
       "              \n",
       "                       [[ 2.0170e-02, -6.9177e-02, -8.7616e-02],\n",
       "                        [-3.3121e-02, -9.8226e-02, -4.9158e-02],\n",
       "                        [ 4.8494e-03, -6.9424e-02, -4.3723e-02]],\n",
       "              \n",
       "                       [[-1.8941e-02, -1.2144e-02, -5.8187e-02],\n",
       "                        [ 5.0650e-03, -1.4795e-02,  3.0147e-02],\n",
       "                        [ 4.7611e-03, -5.2638e-02, -3.6291e-02]],\n",
       "              \n",
       "                       [[-1.2149e-03, -6.5774e-02,  8.2520e-03],\n",
       "                        [-7.4425e-03,  4.0897e-02,  2.4947e-02],\n",
       "                        [ 7.8887e-02, -3.4749e-03, -7.7887e-02]],\n",
       "              \n",
       "                       [[ 4.7119e-02, -7.1240e-02, -1.4489e-02],\n",
       "                        [-3.4132e-02, -3.9997e-02, -3.9000e-02],\n",
       "                        [ 9.6863e-02,  6.0342e-02,  2.9213e-02]],\n",
       "              \n",
       "                       [[ 9.8975e-02, -9.5524e-02,  1.7010e-02],\n",
       "                        [ 6.7481e-02,  7.0022e-02, -8.3890e-02],\n",
       "                        [ 3.7514e-02, -6.0050e-02, -4.1187e-03]],\n",
       "              \n",
       "                       [[-2.1996e-02, -8.8013e-02, -1.0055e-01],\n",
       "                        [-6.9349e-02,  4.7832e-02,  4.8218e-02],\n",
       "                        [-9.1681e-02, -3.9586e-02,  1.7218e-03]],\n",
       "              \n",
       "                       [[-9.1135e-02,  5.9393e-02,  9.5473e-02],\n",
       "                        [ 1.8643e-02, -7.8321e-02,  2.4580e-02],\n",
       "                        [ 3.8265e-02,  8.3468e-02, -5.6085e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.4437e-02,  4.6312e-02,  6.5624e-03],\n",
       "                        [-3.4345e-02, -4.4169e-02, -5.4351e-02],\n",
       "                        [ 8.5328e-02, -1.8187e-02,  7.6022e-02]],\n",
       "              \n",
       "                       [[ 9.4094e-02,  1.3353e-02,  2.2454e-02],\n",
       "                        [-7.1789e-03,  7.2397e-02, -9.4983e-02],\n",
       "                        [ 4.1919e-02, -1.7174e-02,  4.8132e-02]],\n",
       "              \n",
       "                       [[-4.6949e-04, -3.9029e-02, -1.1379e-02],\n",
       "                        [ 5.6920e-02, -7.3210e-02, -6.6629e-02],\n",
       "                        [-2.3611e-02, -3.8235e-02,  4.1409e-02]],\n",
       "              \n",
       "                       [[ 7.0937e-02, -1.1289e-02,  9.9672e-02],\n",
       "                        [-4.4042e-02, -5.9151e-02, -4.7191e-02],\n",
       "                        [-7.2624e-02, -7.3885e-02, -9.3921e-02]],\n",
       "              \n",
       "                       [[-9.3422e-02,  2.7512e-02,  6.4284e-02],\n",
       "                        [ 9.8963e-02,  8.9787e-02, -6.0709e-03],\n",
       "                        [ 2.0454e-02, -6.3068e-02,  4.0743e-02]],\n",
       "              \n",
       "                       [[-1.0107e-01,  4.9719e-02,  1.9334e-02],\n",
       "                        [ 3.2393e-02,  3.8595e-02, -4.8394e-02],\n",
       "                        [ 9.0452e-02,  5.0307e-02,  6.9243e-02]],\n",
       "              \n",
       "                       [[ 1.3922e-02,  6.6196e-02,  7.0941e-02],\n",
       "                        [ 4.7775e-02,  8.0297e-02, -1.9119e-02],\n",
       "                        [ 6.9310e-02,  2.4286e-02,  6.3424e-02]],\n",
       "              \n",
       "                       [[ 1.0267e-01,  2.3869e-02, -3.9124e-02],\n",
       "                        [-1.0488e-02,  2.9676e-02,  1.7773e-02],\n",
       "                        [-2.8795e-02,  8.2590e-02,  6.3331e-02]],\n",
       "              \n",
       "                       [[-6.5475e-02, -8.5889e-03, -1.0119e-02],\n",
       "                        [-6.6063e-02,  1.5374e-02, -3.2360e-02],\n",
       "                        [-5.4419e-02, -3.3894e-02, -3.7584e-02]],\n",
       "              \n",
       "                       [[ 1.0084e-01,  4.0432e-02,  1.0373e-01],\n",
       "                        [ 2.8903e-02,  2.3868e-02,  4.3333e-02],\n",
       "                        [ 1.8092e-02, -8.2722e-02, -6.2334e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5538e-02,  1.5846e-03,  3.9709e-02],\n",
       "                        [ 4.0588e-02,  8.3623e-02,  2.1458e-02],\n",
       "                        [-3.5975e-02, -7.9271e-02, -7.7203e-02]],\n",
       "              \n",
       "                       [[-6.2965e-02,  3.1792e-02,  5.6950e-02],\n",
       "                        [ 9.2224e-02, -3.3342e-02, -8.3150e-03],\n",
       "                        [-3.1303e-02, -3.8517e-04,  3.3837e-02]],\n",
       "              \n",
       "                       [[-2.3160e-03,  4.8799e-03,  1.3354e-02],\n",
       "                        [ 3.9256e-02, -3.1981e-02, -6.2855e-02],\n",
       "                        [ 2.4869e-02, -1.2481e-02, -4.7753e-02]],\n",
       "              \n",
       "                       [[ 4.4268e-02,  9.5597e-04, -1.5333e-02],\n",
       "                        [-5.1027e-02, -1.3868e-02, -8.9632e-02],\n",
       "                        [ 2.3980e-02,  1.5818e-03,  6.3966e-02]],\n",
       "              \n",
       "                       [[ 6.8063e-03,  8.4277e-03,  2.8715e-02],\n",
       "                        [ 8.0210e-02, -4.9812e-02,  6.2930e-02],\n",
       "                        [ 2.5779e-02, -7.0320e-02,  3.6702e-02]],\n",
       "              \n",
       "                       [[-6.3217e-02, -3.3181e-02, -5.0245e-02],\n",
       "                        [-7.1711e-02,  8.3017e-02, -9.4217e-02],\n",
       "                        [ 5.2706e-02, -9.4870e-02, -1.2829e-02]],\n",
       "              \n",
       "                       [[ 6.2868e-03,  7.4937e-02, -3.8147e-02],\n",
       "                        [ 3.0340e-02,  1.6329e-02,  6.2021e-02],\n",
       "                        [ 6.2667e-03,  3.9470e-02, -6.3677e-02]],\n",
       "              \n",
       "                       [[-7.3250e-02,  9.3928e-02, -7.6808e-02],\n",
       "                        [-1.7945e-02, -1.2742e-02,  1.0308e-01],\n",
       "                        [-2.2780e-02, -8.0249e-02, -2.6721e-02]],\n",
       "              \n",
       "                       [[ 5.4372e-02,  4.1773e-02,  8.7204e-02],\n",
       "                        [-2.1579e-02,  4.9653e-02, -9.9194e-02],\n",
       "                        [ 4.0787e-02,  4.8432e-02,  6.7998e-02]],\n",
       "              \n",
       "                       [[-6.0446e-02, -2.8142e-02,  2.5502e-02],\n",
       "                        [-7.4905e-02, -8.3851e-02, -1.0141e-01],\n",
       "                        [ 5.8842e-03,  6.5458e-02,  2.7075e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.4263e-03,  3.6727e-02, -6.6240e-02],\n",
       "                        [ 1.1113e-02, -2.6186e-02, -5.2193e-02],\n",
       "                        [ 9.0902e-02, -8.1550e-02,  1.5448e-02]],\n",
       "              \n",
       "                       [[-9.2624e-02, -3.5762e-03, -4.6840e-02],\n",
       "                        [ 3.4695e-02, -5.9191e-02,  6.7466e-02],\n",
       "                        [-8.5536e-02,  6.3313e-02, -7.9181e-02]],\n",
       "              \n",
       "                       [[ 5.6456e-02, -4.4384e-02, -2.4556e-04],\n",
       "                        [-1.9238e-02,  6.8414e-02,  3.4546e-02],\n",
       "                        [-9.2887e-02,  9.6914e-03, -7.2718e-02]],\n",
       "              \n",
       "                       [[ 7.8800e-02,  1.7319e-02, -2.7109e-02],\n",
       "                        [-5.3777e-02,  3.6485e-02, -6.3129e-02],\n",
       "                        [ 4.9992e-02,  5.7519e-02,  6.4701e-02]],\n",
       "              \n",
       "                       [[ 2.7537e-02, -9.2272e-02,  7.5823e-02],\n",
       "                        [-3.2700e-02, -3.1163e-02, -1.1325e-02],\n",
       "                        [ 7.7068e-02,  8.1052e-02,  1.6276e-02]],\n",
       "              \n",
       "                       [[ 5.0296e-02, -9.8241e-02,  2.4900e-04],\n",
       "                        [-9.3254e-02,  3.5876e-02, -7.5099e-02],\n",
       "                        [-3.7568e-02,  7.3684e-02,  1.0074e-01]],\n",
       "              \n",
       "                       [[-6.3286e-02, -5.8503e-02,  1.3055e-02],\n",
       "                        [ 4.1437e-02, -1.7168e-02, -3.2918e-02],\n",
       "                        [-6.9237e-02,  4.4997e-02,  1.0328e-01]],\n",
       "              \n",
       "                       [[-5.1026e-02,  4.9718e-02,  5.1481e-02],\n",
       "                        [ 8.4728e-02, -1.2001e-02,  3.3202e-03],\n",
       "                        [ 7.7444e-02,  6.6631e-02,  1.0411e-01]],\n",
       "              \n",
       "                       [[-3.0207e-02,  4.1709e-02,  7.3605e-02],\n",
       "                        [-7.1553e-02,  2.0940e-02, -2.3586e-02],\n",
       "                        [ 6.7760e-02, -4.7342e-02,  7.3933e-03]],\n",
       "              \n",
       "                       [[ 6.3067e-02, -9.6567e-02, -8.9004e-02],\n",
       "                        [-5.3989e-02,  6.7611e-02,  7.0680e-02],\n",
       "                        [-7.1991e-02,  2.0100e-02, -5.5854e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8926e-02,  9.0907e-02,  5.0914e-02],\n",
       "                        [-2.8828e-02,  1.5516e-02,  2.0424e-02],\n",
       "                        [ 2.4691e-02, -3.6079e-02, -6.2074e-02]],\n",
       "              \n",
       "                       [[ 6.9788e-02,  1.4164e-02,  4.4119e-02],\n",
       "                        [-3.9922e-02,  5.1057e-02,  7.6713e-02],\n",
       "                        [ 6.4107e-02,  2.8660e-02,  1.0371e-01]],\n",
       "              \n",
       "                       [[-2.3053e-04,  2.2441e-02,  1.0015e-01],\n",
       "                        [ 1.0245e-01, -4.4506e-02,  9.4953e-02],\n",
       "                        [ 3.8902e-02, -1.1799e-02,  9.2038e-02]],\n",
       "              \n",
       "                       [[-5.4605e-02,  6.8490e-02,  1.0445e-01],\n",
       "                        [-7.2701e-02, -6.2201e-02, -1.0445e-01],\n",
       "                        [-1.8970e-02, -9.5733e-02, -3.5304e-02]],\n",
       "              \n",
       "                       [[ 3.2002e-02,  7.4511e-02,  5.8717e-02],\n",
       "                        [ 5.8511e-02,  4.3730e-02, -6.5378e-02],\n",
       "                        [-8.3694e-02,  4.3696e-03,  1.0009e-01]],\n",
       "              \n",
       "                       [[ 5.9351e-03, -9.0662e-03, -7.1545e-02],\n",
       "                        [-5.2266e-02, -8.1256e-02,  8.4398e-02],\n",
       "                        [-1.7174e-02, -9.3119e-02,  1.1308e-02]],\n",
       "              \n",
       "                       [[ 7.6494e-03, -1.3023e-02,  3.7733e-02],\n",
       "                        [ 5.6687e-02, -9.9128e-02, -8.0753e-02],\n",
       "                        [-5.0639e-03, -9.7729e-02, -9.5750e-02]],\n",
       "              \n",
       "                       [[ 9.3067e-02, -8.0174e-03, -5.2113e-02],\n",
       "                        [-3.6157e-02, -8.2295e-02,  8.2258e-02],\n",
       "                        [-2.2857e-02, -5.9265e-02, -7.9944e-02]],\n",
       "              \n",
       "                       [[ 6.1611e-02, -1.4571e-02, -1.1074e-02],\n",
       "                        [-2.7473e-02, -5.0883e-02,  1.8751e-02],\n",
       "                        [ 8.1099e-02, -6.1093e-02,  5.0504e-03]],\n",
       "              \n",
       "                       [[-8.0165e-02, -4.9426e-02,  9.2525e-02],\n",
       "                        [ 1.1052e-03,  1.0154e-01, -1.8468e-02],\n",
       "                        [-5.7453e-02, -6.2981e-02,  9.3426e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.1058e-02,  5.5318e-02,  2.6203e-02],\n",
       "                        [ 3.1107e-02,  5.9476e-02, -2.7577e-02],\n",
       "                        [ 6.5223e-02, -8.3982e-02, -3.7087e-02]],\n",
       "              \n",
       "                       [[ 7.7164e-02,  3.1283e-02, -1.4038e-02],\n",
       "                        [-2.4616e-02, -6.4364e-02,  6.4098e-02],\n",
       "                        [-3.3520e-03, -3.5664e-03,  2.4929e-02]],\n",
       "              \n",
       "                       [[ 7.7787e-02, -5.3778e-02, -3.6303e-02],\n",
       "                        [ 7.1429e-02,  5.9532e-02, -5.1855e-02],\n",
       "                        [-1.0428e-01,  1.9555e-02,  5.5434e-02]],\n",
       "              \n",
       "                       [[ 2.5178e-02,  7.4768e-02, -8.3640e-02],\n",
       "                        [ 5.3156e-02, -6.5531e-02,  5.9325e-02],\n",
       "                        [ 7.8394e-02,  3.3385e-02,  8.5284e-02]],\n",
       "              \n",
       "                       [[-6.9481e-02, -9.4275e-02, -1.0135e-01],\n",
       "                        [ 6.6179e-02,  3.6926e-02, -7.7188e-02],\n",
       "                        [ 5.1048e-02,  9.6177e-02, -1.0394e-01]],\n",
       "              \n",
       "                       [[ 7.6466e-02,  1.6167e-02,  9.8053e-03],\n",
       "                        [ 9.4847e-02,  9.5458e-02,  4.4414e-02],\n",
       "                        [ 8.3288e-02,  4.3853e-02,  1.7176e-02]],\n",
       "              \n",
       "                       [[-9.2656e-02,  1.9689e-02, -7.4993e-02],\n",
       "                        [ 3.2452e-02,  1.8598e-02,  2.3681e-03],\n",
       "                        [-7.2071e-02, -6.3899e-02,  7.7912e-02]],\n",
       "              \n",
       "                       [[ 5.1336e-02,  5.5576e-02, -3.1410e-02],\n",
       "                        [-1.8151e-02, -2.7014e-02,  7.2489e-02],\n",
       "                        [-4.5504e-02,  6.6394e-02,  7.2679e-02]],\n",
       "              \n",
       "                       [[-9.6403e-02,  6.4369e-04, -2.0076e-02],\n",
       "                        [-5.8273e-02,  4.5507e-02, -1.2807e-02],\n",
       "                        [ 9.2287e-02, -6.5976e-02,  4.8976e-02]],\n",
       "              \n",
       "                       [[-8.9998e-02, -5.2833e-02,  7.1903e-03],\n",
       "                        [ 8.3283e-02,  5.5521e-02, -8.6550e-02],\n",
       "                        [ 1.1676e-02, -6.2138e-02,  4.5674e-03]]]], device='mps:0')),\n",
       "             ('conv_block_2.0.bias',\n",
       "              tensor([-0.0878, -0.0309,  0.0723, -0.0967, -0.1005,  0.0192,  0.0144, -0.0193,\n",
       "                       0.0920, -0.0635], device='mps:0')),\n",
       "             ('conv_block_2.2.weight',\n",
       "              tensor([[[[-6.3992e-02, -7.8791e-02, -1.9619e-02],\n",
       "                        [-2.6901e-02,  6.5222e-02, -5.9186e-03],\n",
       "                        [ 3.3663e-02, -4.3804e-02,  8.5507e-02]],\n",
       "              \n",
       "                       [[ 8.8862e-02, -9.4401e-02, -2.7090e-02],\n",
       "                        [-8.9439e-02,  4.4781e-02, -9.2094e-02],\n",
       "                        [-4.9839e-02,  1.0532e-01, -1.0066e-01]],\n",
       "              \n",
       "                       [[ 7.7771e-02,  8.9049e-03,  8.4289e-02],\n",
       "                        [-5.3494e-02,  6.9236e-02,  1.2718e-02],\n",
       "                        [ 8.1073e-03,  7.1945e-02, -1.0019e-01]],\n",
       "              \n",
       "                       [[-8.4902e-02,  1.0180e-01, -6.3298e-02],\n",
       "                        [-7.5980e-02, -5.1539e-03, -3.3742e-02],\n",
       "                        [-1.4421e-02, -7.0623e-02,  3.8034e-02]],\n",
       "              \n",
       "                       [[-9.0703e-02,  8.5374e-03,  6.1510e-02],\n",
       "                        [ 2.0253e-02,  1.4006e-02,  1.5418e-02],\n",
       "                        [-3.0880e-02, -2.0080e-02, -4.4450e-02]],\n",
       "              \n",
       "                       [[-7.1207e-02, -5.5810e-02,  1.0420e-01],\n",
       "                        [-1.7641e-02,  3.6924e-02,  7.2896e-02],\n",
       "                        [-8.2343e-03, -5.6707e-02, -7.1419e-02]],\n",
       "              \n",
       "                       [[-3.8833e-02,  3.7624e-02, -8.8771e-02],\n",
       "                        [-1.2870e-02,  4.0096e-02,  8.5999e-02],\n",
       "                        [ 3.1721e-02,  2.0846e-02,  7.2162e-02]],\n",
       "              \n",
       "                       [[ 4.8708e-02,  3.5661e-02, -3.2682e-02],\n",
       "                        [-8.4528e-02, -2.2769e-02, -1.9117e-02],\n",
       "                        [ 7.7410e-03, -1.1593e-02,  4.2616e-02]],\n",
       "              \n",
       "                       [[ 7.0050e-02, -4.2735e-02, -1.0002e-01],\n",
       "                        [-5.4081e-02, -5.0436e-02,  5.9750e-02],\n",
       "                        [-6.7994e-02, -9.9145e-03, -2.2340e-02]],\n",
       "              \n",
       "                       [[-6.3976e-02,  4.7780e-02, -4.3909e-02],\n",
       "                        [-5.4531e-03, -7.4112e-02, -1.0632e-02],\n",
       "                        [ 1.4977e-02, -4.2894e-03, -3.9386e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.1315e-02, -2.7311e-02, -5.8439e-02],\n",
       "                        [-7.7732e-02, -2.2329e-02, -9.9578e-02],\n",
       "                        [ 8.7492e-02, -5.0357e-02, -4.3684e-02]],\n",
       "              \n",
       "                       [[ 9.7439e-03,  2.7326e-02, -9.9393e-03],\n",
       "                        [ 7.2313e-02, -6.1448e-02,  3.7777e-02],\n",
       "                        [-2.3773e-04, -8.5747e-02, -4.0824e-02]],\n",
       "              \n",
       "                       [[ 2.6825e-02,  2.0138e-02,  7.6647e-02],\n",
       "                        [ 7.0518e-02, -5.7493e-02, -4.5013e-02],\n",
       "                        [-2.2351e-02, -7.5517e-02, -2.8459e-02]],\n",
       "              \n",
       "                       [[-8.6258e-02,  4.0092e-02,  7.4583e-02],\n",
       "                        [ 8.3459e-03, -7.5460e-02, -7.9827e-02],\n",
       "                        [-4.1036e-02,  3.0659e-02,  2.5711e-03]],\n",
       "              \n",
       "                       [[ 1.9166e-02,  9.9346e-02,  4.8956e-02],\n",
       "                        [ 2.2665e-02, -2.1327e-02,  4.9864e-02],\n",
       "                        [ 3.8563e-02, -9.4879e-02, -6.2266e-02]],\n",
       "              \n",
       "                       [[ 3.5381e-03,  3.9997e-02,  5.1282e-02],\n",
       "                        [-6.2748e-02, -1.0458e-01, -5.4909e-03],\n",
       "                        [-1.2050e-02,  3.0588e-02, -2.8988e-02]],\n",
       "              \n",
       "                       [[ 8.0588e-02,  7.0333e-03,  7.6975e-02],\n",
       "                        [-7.3398e-02,  4.2167e-02,  1.2560e-02],\n",
       "                        [-5.2720e-02,  5.2256e-02, -1.0372e-01]],\n",
       "              \n",
       "                       [[ 8.5220e-02,  8.4947e-03,  1.0178e-02],\n",
       "                        [ 4.8746e-02,  8.7503e-03,  4.5184e-02],\n",
       "                        [ 6.7063e-02, -8.2268e-02,  6.9735e-02]],\n",
       "              \n",
       "                       [[-1.5784e-02, -2.4513e-02,  2.1217e-02],\n",
       "                        [ 8.2446e-02, -5.7302e-02, -7.1039e-02],\n",
       "                        [ 6.5418e-02, -4.9507e-02,  3.3937e-02]],\n",
       "              \n",
       "                       [[-1.5530e-02,  2.9014e-02,  8.0439e-02],\n",
       "                        [-5.3421e-02, -5.1151e-02,  5.1716e-02],\n",
       "                        [ 5.7714e-03, -1.1601e-02, -9.2590e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.9309e-02, -3.9919e-03, -1.9415e-02],\n",
       "                        [-4.3269e-02, -2.0801e-02,  5.1233e-02],\n",
       "                        [-2.4227e-03,  9.0147e-02, -6.0858e-03]],\n",
       "              \n",
       "                       [[-1.5122e-02,  5.9498e-02, -2.7275e-03],\n",
       "                        [-2.1039e-02,  3.5231e-02,  8.3129e-02],\n",
       "                        [ 2.6305e-02,  7.3398e-02,  6.8309e-02]],\n",
       "              \n",
       "                       [[ 2.9810e-02,  3.6650e-02,  3.4014e-02],\n",
       "                        [ 1.0934e-02,  8.9675e-02,  9.7308e-02],\n",
       "                        [ 3.7524e-02, -5.2640e-03,  9.4509e-02]],\n",
       "              \n",
       "                       [[-8.2042e-02,  7.7453e-02,  5.5849e-02],\n",
       "                        [ 6.7687e-02, -8.0992e-03, -7.8646e-02],\n",
       "                        [ 7.5193e-02, -4.6091e-02,  2.7734e-02]],\n",
       "              \n",
       "                       [[ 5.9719e-02, -9.8508e-02,  6.9954e-03],\n",
       "                        [-3.7444e-02,  7.4815e-02, -6.7114e-02],\n",
       "                        [ 6.4001e-02,  6.5730e-02,  5.8156e-02]],\n",
       "              \n",
       "                       [[ 1.0119e-01,  1.5964e-02, -9.5541e-02],\n",
       "                        [ 7.5248e-02,  9.6499e-03,  2.0918e-03],\n",
       "                        [-1.0041e-01, -2.3691e-02, -5.1162e-02]],\n",
       "              \n",
       "                       [[ 1.0324e-01,  7.5054e-02,  7.8634e-02],\n",
       "                        [ 7.2188e-02, -6.5340e-02, -4.5270e-02],\n",
       "                        [-4.1252e-02, -4.2257e-02,  8.2054e-02]],\n",
       "              \n",
       "                       [[ 3.5815e-02,  8.4470e-02, -4.9309e-03],\n",
       "                        [-9.3965e-02, -3.0582e-02,  7.4081e-02],\n",
       "                        [ 6.4174e-02,  3.2632e-02, -3.0919e-02]],\n",
       "              \n",
       "                       [[-9.8386e-02, -5.6639e-02,  5.4958e-02],\n",
       "                        [-4.2518e-02,  5.0421e-02,  2.8781e-02],\n",
       "                        [-4.0486e-02,  6.4202e-02, -3.3871e-02]],\n",
       "              \n",
       "                       [[-3.5020e-03, -4.0152e-02, -9.9988e-02],\n",
       "                        [ 1.6996e-02,  3.0460e-02, -5.3072e-02],\n",
       "                        [ 6.4663e-02, -9.4558e-02, -1.0161e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.5106e-02, -3.6430e-02, -1.1707e-02],\n",
       "                        [-2.0370e-02,  4.8108e-02, -9.2510e-02],\n",
       "                        [ 1.5521e-02,  1.8254e-03,  2.7842e-02]],\n",
       "              \n",
       "                       [[ 1.0479e-01,  6.4874e-02, -5.8366e-02],\n",
       "                        [-8.6378e-02, -2.5520e-02, -5.2876e-02],\n",
       "                        [ 3.6820e-02,  9.6628e-04,  8.4783e-02]],\n",
       "              \n",
       "                       [[ 4.1405e-02, -1.9382e-02,  3.6229e-03],\n",
       "                        [ 2.5244e-02, -1.3080e-02,  8.5058e-02],\n",
       "                        [-8.2420e-02,  5.1377e-02, -6.7192e-02]],\n",
       "              \n",
       "                       [[-9.2347e-02, -2.1640e-02,  5.1366e-02],\n",
       "                        [ 7.4478e-02,  2.6452e-02, -9.1104e-03],\n",
       "                        [-5.9092e-03, -4.2731e-02, -9.4592e-03]],\n",
       "              \n",
       "                       [[-7.2831e-03,  8.9699e-02,  6.1690e-02],\n",
       "                        [-8.4351e-02,  4.3604e-04, -6.4834e-02],\n",
       "                        [-1.6733e-02, -8.3776e-02,  2.7402e-02]],\n",
       "              \n",
       "                       [[-7.6008e-02,  1.0406e-01,  7.9605e-02],\n",
       "                        [-7.2559e-02, -9.9239e-02,  4.1128e-03],\n",
       "                        [-2.9425e-02,  3.0945e-02, -7.1353e-02]],\n",
       "              \n",
       "                       [[ 4.3148e-02, -9.1047e-02, -5.5632e-02],\n",
       "                        [-5.5414e-02,  5.1007e-02, -2.7597e-03],\n",
       "                        [-1.0130e-01, -6.0201e-02, -4.8781e-02]],\n",
       "              \n",
       "                       [[-9.7802e-02,  1.3497e-02,  3.7561e-02],\n",
       "                        [-1.9340e-02, -4.1947e-02, -6.3926e-04],\n",
       "                        [-8.3725e-02, -6.4184e-02, -2.4040e-03]],\n",
       "              \n",
       "                       [[ 9.3643e-02, -3.2414e-02,  5.2247e-02],\n",
       "                        [-4.1484e-02, -2.8060e-02, -1.0034e-01],\n",
       "                        [ 8.7330e-02,  1.0264e-01, -2.2139e-03]],\n",
       "              \n",
       "                       [[ 6.6974e-02,  8.6219e-02,  5.2359e-02],\n",
       "                        [ 5.4288e-02, -1.0035e-01, -9.9050e-02],\n",
       "                        [-8.0906e-02,  3.2970e-02, -9.1177e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.0464e-02, -5.1092e-02, -9.7154e-02],\n",
       "                        [ 1.4203e-04,  1.5207e-02, -6.1686e-02],\n",
       "                        [ 6.9018e-02, -4.0018e-02, -2.9676e-02]],\n",
       "              \n",
       "                       [[ 8.0309e-02,  9.0499e-02, -1.2093e-02],\n",
       "                        [-7.5671e-02, -5.2881e-02,  1.3423e-02],\n",
       "                        [ 6.1790e-02,  5.2477e-02, -4.6547e-02]],\n",
       "              \n",
       "                       [[-9.9650e-02, -9.2249e-02, -3.3537e-02],\n",
       "                        [ 1.3223e-03, -4.7347e-02, -8.3348e-02],\n",
       "                        [ 1.1109e-02, -8.3668e-02, -8.0946e-02]],\n",
       "              \n",
       "                       [[-8.5692e-02, -2.8563e-02,  9.3104e-02],\n",
       "                        [ 4.1207e-02, -1.2498e-02,  2.1694e-02],\n",
       "                        [ 4.1975e-02,  6.1414e-04, -8.5020e-02]],\n",
       "              \n",
       "                       [[-6.4944e-02, -7.1610e-02, -2.6766e-03],\n",
       "                        [-9.6492e-02, -1.9166e-02, -3.8545e-02],\n",
       "                        [ 1.0345e-01,  8.5679e-02,  6.1227e-02]],\n",
       "              \n",
       "                       [[ 5.9116e-03, -3.4129e-02,  2.6887e-02],\n",
       "                        [-7.2830e-02, -4.4957e-02, -2.1175e-02],\n",
       "                        [-2.4766e-02, -9.9854e-02,  4.1903e-02]],\n",
       "              \n",
       "                       [[ 8.6803e-02, -5.8141e-02,  2.8415e-02],\n",
       "                        [-1.2225e-02, -3.8445e-03,  6.1443e-03],\n",
       "                        [ 9.1346e-02,  1.4124e-02, -6.6690e-02]],\n",
       "              \n",
       "                       [[-3.7917e-02,  5.1495e-02,  3.2893e-02],\n",
       "                        [ 2.0487e-03, -1.3912e-02, -4.1012e-02],\n",
       "                        [-3.7413e-02, -5.5602e-02,  1.7273e-02]],\n",
       "              \n",
       "                       [[ 2.9603e-02,  8.0717e-02, -2.3813e-02],\n",
       "                        [ 7.5461e-03,  6.8125e-02,  4.5852e-02],\n",
       "                        [ 1.3544e-02,  3.2390e-02,  5.4714e-03]],\n",
       "              \n",
       "                       [[-9.0419e-02,  4.0636e-03, -2.3040e-02],\n",
       "                        [ 9.5123e-02,  9.5145e-02,  2.0912e-02],\n",
       "                        [ 9.4215e-02, -5.4288e-02,  9.1619e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.0756e-02, -4.0288e-03, -8.4592e-02],\n",
       "                        [-3.4015e-02, -2.8189e-02,  1.7411e-03],\n",
       "                        [-9.5569e-02,  1.9535e-02, -4.3839e-02]],\n",
       "              \n",
       "                       [[-2.6989e-02, -5.4443e-02, -2.2255e-02],\n",
       "                        [-9.7896e-02, -5.5885e-02,  9.7108e-03],\n",
       "                        [ 6.9072e-02,  9.5790e-02, -7.9737e-02]],\n",
       "              \n",
       "                       [[ 4.4264e-02, -5.9419e-02, -8.1498e-02],\n",
       "                        [-4.6417e-03, -6.0468e-02, -9.0783e-02],\n",
       "                        [-9.8509e-02, -7.0556e-02,  8.6619e-02]],\n",
       "              \n",
       "                       [[ 5.8788e-02, -4.1726e-02, -7.0553e-02],\n",
       "                        [-8.1085e-02, -6.2246e-02, -4.3376e-02],\n",
       "                        [ 6.3308e-02,  3.4496e-02, -4.0622e-02]],\n",
       "              \n",
       "                       [[ 7.2567e-02, -6.5484e-02, -8.5876e-02],\n",
       "                        [ 2.3006e-02, -5.8123e-02,  2.9987e-02],\n",
       "                        [ 8.9306e-02, -4.9849e-02, -7.3556e-02]],\n",
       "              \n",
       "                       [[ 3.9676e-02, -9.5200e-02,  9.4044e-02],\n",
       "                        [-4.9780e-02,  5.0961e-02, -8.3818e-02],\n",
       "                        [-7.1348e-02,  1.1611e-02,  3.7463e-02]],\n",
       "              \n",
       "                       [[ 8.1734e-02,  8.8158e-02, -6.0623e-03],\n",
       "                        [-1.3552e-02,  1.7424e-02, -2.4486e-02],\n",
       "                        [ 3.5882e-03, -9.9828e-02, -8.6531e-02]],\n",
       "              \n",
       "                       [[ 7.2233e-02, -6.1597e-02,  8.3008e-02],\n",
       "                        [ 1.1568e-02,  2.5676e-02,  9.5804e-02],\n",
       "                        [-5.8628e-02, -1.6640e-02,  1.8675e-02]],\n",
       "              \n",
       "                       [[ 3.6012e-02, -1.0259e-01,  3.7464e-02],\n",
       "                        [-6.2163e-02,  1.3846e-02,  7.1315e-02],\n",
       "                        [-1.0500e-02, -3.3346e-03, -7.8757e-03]],\n",
       "              \n",
       "                       [[ 8.7962e-02,  5.9907e-02,  1.7727e-02],\n",
       "                        [-6.3437e-02, -5.7241e-02,  8.3964e-02],\n",
       "                        [ 7.5834e-02,  6.1033e-02, -8.2189e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.2092e-02, -1.0076e-02,  7.7661e-02],\n",
       "                        [ 9.1553e-02,  1.1554e-02, -4.3863e-02],\n",
       "                        [ 9.9153e-02, -5.4931e-02,  6.8876e-02]],\n",
       "              \n",
       "                       [[-1.0108e-01, -3.3153e-02, -9.1902e-02],\n",
       "                        [-4.7284e-02,  4.4759e-02, -7.5529e-02],\n",
       "                        [-9.1158e-02,  7.5371e-02,  5.6270e-02]],\n",
       "              \n",
       "                       [[-1.1527e-03, -7.4309e-02, -2.7927e-02],\n",
       "                        [-3.4129e-02,  6.5100e-02, -3.4478e-02],\n",
       "                        [-3.0360e-02, -7.4720e-02, -4.9646e-02]],\n",
       "              \n",
       "                       [[ 5.7074e-02,  6.7914e-02,  1.5315e-02],\n",
       "                        [-3.9549e-02,  1.0124e-01,  2.0806e-02],\n",
       "                        [-4.0688e-02, -3.6535e-02, -1.4752e-02]],\n",
       "              \n",
       "                       [[ 4.9974e-02,  3.8555e-02,  7.6418e-02],\n",
       "                        [-4.7494e-03,  8.7183e-02, -4.2816e-02],\n",
       "                        [-4.8547e-02, -3.8927e-02, -9.8896e-02]],\n",
       "              \n",
       "                       [[-6.9195e-02, -9.5382e-02, -6.2294e-03],\n",
       "                        [ 9.9374e-04, -2.7358e-02, -7.2035e-02],\n",
       "                        [ 9.5637e-02, -3.4926e-02,  5.0233e-02]],\n",
       "              \n",
       "                       [[ 7.3408e-02, -6.9291e-02, -1.3179e-02],\n",
       "                        [ 6.0923e-02,  1.0218e-01, -1.3299e-02],\n",
       "                        [ 7.6382e-02, -8.2732e-02, -6.8489e-02]],\n",
       "              \n",
       "                       [[ 8.6682e-02, -9.9801e-03,  1.0414e-01],\n",
       "                        [ 7.6651e-03, -4.3714e-02,  1.0011e-01],\n",
       "                        [ 9.2179e-02,  9.7826e-03, -6.3900e-02]],\n",
       "              \n",
       "                       [[-4.5639e-03, -5.0693e-02,  7.6810e-02],\n",
       "                        [ 4.8829e-03,  2.2191e-02,  6.3927e-02],\n",
       "                        [ 3.4916e-02, -6.5803e-02,  8.7566e-02]],\n",
       "              \n",
       "                       [[ 6.4758e-02, -6.5073e-02,  7.9700e-02],\n",
       "                        [ 2.9905e-02, -2.0750e-02, -7.5385e-02],\n",
       "                        [-1.7490e-02, -1.0335e-01,  6.0163e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.6343e-02, -3.0347e-02,  9.7720e-02],\n",
       "                        [-3.9032e-02,  1.8051e-02, -7.3459e-02],\n",
       "                        [-4.4565e-03,  4.2610e-02,  4.5403e-02]],\n",
       "              \n",
       "                       [[-3.5346e-03, -5.3154e-02,  7.3680e-02],\n",
       "                        [ 6.9788e-02,  1.6916e-02, -4.8475e-02],\n",
       "                        [ 2.2349e-02,  2.8186e-04,  9.6302e-02]],\n",
       "              \n",
       "                       [[ 1.5621e-02,  8.1301e-03,  7.2057e-03],\n",
       "                        [ 5.6079e-02, -1.3024e-03,  9.0351e-02],\n",
       "                        [ 5.4917e-02, -7.9650e-02, -1.2063e-06]],\n",
       "              \n",
       "                       [[-8.9472e-02, -8.0934e-02,  2.0480e-02],\n",
       "                        [ 2.3687e-02, -9.2246e-03,  1.0019e-01],\n",
       "                        [-5.6627e-02, -4.4176e-02, -1.6881e-02]],\n",
       "              \n",
       "                       [[ 6.3911e-04, -8.9284e-03,  9.4909e-02],\n",
       "                        [-4.4519e-02, -5.5137e-02,  9.0599e-03],\n",
       "                        [ 7.9171e-02,  2.5019e-02,  5.6787e-02]],\n",
       "              \n",
       "                       [[ 2.0406e-02,  8.9839e-02,  6.3311e-02],\n",
       "                        [ 7.5428e-02, -1.4198e-02, -8.7268e-02],\n",
       "                        [-5.0002e-02,  3.5910e-02,  7.3950e-02]],\n",
       "              \n",
       "                       [[-4.1184e-02,  8.7218e-02,  1.5150e-02],\n",
       "                        [ 4.1869e-04,  4.1093e-03, -1.8623e-02],\n",
       "                        [ 9.8683e-02,  4.5784e-03,  6.4564e-02]],\n",
       "              \n",
       "                       [[-8.8967e-02, -5.4309e-02,  1.1852e-02],\n",
       "                        [ 8.4169e-02,  5.0184e-02,  2.0076e-02],\n",
       "                        [-1.0414e-01,  1.9816e-03, -6.9581e-02]],\n",
       "              \n",
       "                       [[-9.0006e-02,  1.4414e-02, -6.6693e-02],\n",
       "                        [ 9.5674e-02, -5.7294e-02,  3.3970e-02],\n",
       "                        [ 6.1871e-02, -8.1928e-02,  5.3946e-02]],\n",
       "              \n",
       "                       [[-1.4114e-02,  5.4619e-02,  1.0201e-01],\n",
       "                        [-4.4922e-02, -4.5653e-02,  8.3753e-02],\n",
       "                        [ 1.1722e-02, -1.0513e-02,  7.9971e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0928e-02, -5.2047e-03,  7.2403e-02],\n",
       "                        [ 4.1195e-02, -6.8180e-02,  2.7398e-02],\n",
       "                        [-8.0368e-02, -5.7245e-02,  6.7779e-02]],\n",
       "              \n",
       "                       [[-2.8093e-02, -5.3691e-02,  7.4717e-03],\n",
       "                        [ 2.5759e-02, -6.5524e-02, -7.1084e-02],\n",
       "                        [-1.0209e-01,  2.7236e-02, -6.8013e-02]],\n",
       "              \n",
       "                       [[ 8.0331e-03, -2.3576e-02, -6.8923e-02],\n",
       "                        [-3.3636e-02, -8.1027e-02, -5.5797e-02],\n",
       "                        [-3.2857e-03, -9.0116e-02, -9.2447e-02]],\n",
       "              \n",
       "                       [[ 7.8958e-02,  9.9188e-03, -4.6618e-02],\n",
       "                        [-3.5047e-03,  7.8168e-02, -8.7939e-02],\n",
       "                        [-5.5886e-02, -7.6226e-02, -7.6634e-03]],\n",
       "              \n",
       "                       [[-3.6274e-03, -8.2146e-02,  7.3163e-02],\n",
       "                        [-8.0946e-02,  9.8414e-02, -7.2560e-02],\n",
       "                        [-1.4446e-02,  1.9710e-02, -4.6852e-02]],\n",
       "              \n",
       "                       [[ 9.6939e-02, -7.2673e-02, -5.8427e-03],\n",
       "                        [-7.7398e-02,  2.9261e-02,  8.9871e-02],\n",
       "                        [ 9.7776e-02,  1.2514e-02, -5.2773e-02]],\n",
       "              \n",
       "                       [[ 1.0244e-01,  7.8667e-03,  7.1317e-02],\n",
       "                        [-5.4751e-02, -4.8920e-02, -8.7504e-02],\n",
       "                        [ 9.6990e-02,  1.7486e-02, -7.5704e-02]],\n",
       "              \n",
       "                       [[ 9.0535e-03, -4.5211e-02,  5.2659e-03],\n",
       "                        [ 3.4988e-02, -5.2308e-02,  1.8394e-02],\n",
       "                        [-6.6553e-02,  2.0312e-02, -1.0178e-01]],\n",
       "              \n",
       "                       [[ 1.6797e-02,  1.0473e-01,  9.7094e-02],\n",
       "                        [ 3.8451e-02,  7.7563e-02,  1.0248e-01],\n",
       "                        [ 2.9870e-02,  3.5156e-02,  1.3707e-02]],\n",
       "              \n",
       "                       [[ 9.3322e-02,  9.0551e-02, -4.9570e-02],\n",
       "                        [-4.3333e-03, -5.3110e-02,  3.7824e-02],\n",
       "                        [-1.0214e-01,  3.7301e-02, -2.8929e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8227e-02,  3.2899e-02, -5.2454e-02],\n",
       "                        [ 5.4687e-02,  4.4762e-02, -8.9602e-02],\n",
       "                        [ 1.0517e-01,  9.0731e-02,  6.5584e-02]],\n",
       "              \n",
       "                       [[-1.0699e-02,  3.7345e-02, -5.7028e-02],\n",
       "                        [-3.5818e-02,  4.9749e-02,  4.6925e-02],\n",
       "                        [ 4.1741e-02, -1.0053e-01,  8.7350e-02]],\n",
       "              \n",
       "                       [[-4.4028e-02,  9.1223e-02,  8.6852e-02],\n",
       "                        [ 3.9070e-02,  1.0502e-01,  6.0528e-02],\n",
       "                        [ 6.1821e-02, -3.5794e-02,  9.7766e-02]],\n",
       "              \n",
       "                       [[ 2.7627e-02,  6.2280e-02, -2.3834e-02],\n",
       "                        [ 7.6340e-02,  9.3509e-02, -8.0770e-02],\n",
       "                        [ 8.6415e-02, -6.9664e-02, -7.2571e-02]],\n",
       "              \n",
       "                       [[-8.8089e-02,  3.0459e-02, -7.9144e-02],\n",
       "                        [-3.9680e-02, -5.2988e-02,  2.8172e-02],\n",
       "                        [-1.0349e-01, -4.8324e-02,  7.7112e-04]],\n",
       "              \n",
       "                       [[ 9.4660e-03, -4.7605e-02,  3.7764e-02],\n",
       "                        [-6.9544e-02, -8.9270e-02, -1.4986e-02],\n",
       "                        [-5.6989e-02,  6.6443e-02, -7.2049e-02]],\n",
       "              \n",
       "                       [[-8.8494e-03,  4.3782e-02, -9.2311e-02],\n",
       "                        [ 8.1599e-02, -4.7895e-02, -2.8684e-02],\n",
       "                        [-6.4480e-02, -3.9279e-02, -4.0645e-02]],\n",
       "              \n",
       "                       [[-9.3801e-02,  3.6019e-02, -3.3768e-04],\n",
       "                        [ 1.0311e-01,  7.1117e-02,  9.1699e-02],\n",
       "                        [ 3.1014e-02,  5.5388e-02,  9.8704e-02]],\n",
       "              \n",
       "                       [[ 8.6545e-02, -8.0996e-02, -2.3636e-02],\n",
       "                        [-1.0166e-01,  3.9877e-03, -3.7229e-02],\n",
       "                        [ 9.1486e-02,  1.6666e-02,  1.1601e-03]],\n",
       "              \n",
       "                       [[-7.6248e-02, -8.2718e-02,  1.6594e-02],\n",
       "                        [-5.2376e-02, -4.8409e-02,  7.3938e-02],\n",
       "                        [-5.4952e-02, -4.6918e-02,  8.0934e-02]]]], device='mps:0')),\n",
       "             ('conv_block_2.2.bias',\n",
       "              tensor([ 0.0412, -0.0599,  0.0319,  0.0531, -0.0936,  0.0197,  0.0241, -0.0041,\n",
       "                       0.1011, -0.0697], device='mps:0')),\n",
       "             ('classifier.1.weight',\n",
       "              tensor([[ 0.0245, -0.0240, -0.0387,  ...,  0.0094, -0.0015, -0.0225],\n",
       "                      [ 0.0228,  0.0067, -0.0439,  ..., -0.0302,  0.0368,  0.0293],\n",
       "                      [ 0.0303,  0.0347, -0.0211,  ...,  0.0207, -0.0423, -0.0240],\n",
       "                      ...,\n",
       "                      [-0.0359, -0.0343,  0.0166,  ...,  0.0324,  0.0113, -0.0143],\n",
       "                      [-0.0294, -0.0316,  0.0251,  ..., -0.0056,  0.0300, -0.0396],\n",
       "                      [-0.0246, -0.0035, -0.0046,  ..., -0.0146, -0.0358,  0.0175]],\n",
       "                     device='mps:0')),\n",
       "             ('classifier.1.bias',\n",
       "              tensor([ 0.0320, -0.0445,  0.0246, -0.0357, -0.0442,  0.0156, -0.0010, -0.0277,\n",
       "                       0.0404,  0.0037], device='mps:0'))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5396,  0.0516,  0.6454,  ..., -0.3673,  0.8711,  0.4256],\n",
       "         [ 0.3662,  1.0114, -0.5997,  ...,  0.8983,  0.2809, -0.2741],\n",
       "         [ 1.2664, -1.4054,  0.3727,  ..., -0.3409,  1.2191, -0.0463],\n",
       "         ...,\n",
       "         [-0.1541,  0.5132, -0.3624,  ..., -0.2360, -0.4609, -0.0035],\n",
       "         [ 0.2981, -0.2432,  1.5012,  ..., -0.6289, -0.7283, -0.5767],\n",
       "         [-0.0386, -0.0781, -0.0388,  ...,  0.2842,  0.4228, -0.1802]],\n",
       "\n",
       "        [[-0.2840, -0.0319, -0.4455,  ..., -0.7956,  1.5599, -1.2449],\n",
       "         [ 0.2753, -0.1262, -0.6541,  ..., -0.2211,  0.1999, -0.8856],\n",
       "         [-0.5404, -1.5489,  0.0249,  ..., -0.5932, -1.0913, -0.3849],\n",
       "         ...,\n",
       "         [ 0.3870, -0.4064, -0.8236,  ...,  0.1734, -0.4330, -0.4951],\n",
       "         [-0.1984, -0.6386,  1.0263,  ..., -0.9401, -0.0585, -0.7833],\n",
       "         [-0.6306, -0.2052, -0.3694,  ..., -1.3248,  0.2456, -0.7134]],\n",
       "\n",
       "        [[ 0.4414,  0.5100,  0.4846,  ..., -0.8484,  0.2638,  1.1258],\n",
       "         [ 0.8117,  0.3191, -0.0157,  ...,  1.2686,  0.2319,  0.5003],\n",
       "         [ 0.3212,  0.0485, -0.2581,  ...,  0.2258,  0.2587, -0.8804],\n",
       "         ...,\n",
       "         [-0.1144, -0.1869,  0.0160,  ..., -0.8346,  0.0974,  0.8421],\n",
       "         [ 0.2941,  0.4417,  0.5866,  ..., -0.1224,  0.4814, -0.4799],\n",
       "         [ 0.6059, -0.0415, -0.2028,  ...,  0.1170,  0.2521, -0.4372]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.2560, -0.0477,  0.6380,  ...,  0.6436,  0.7553, -0.7055],\n",
       "         [ 1.5595, -0.2209, -0.9486,  ..., -0.4876,  0.7754,  0.0750],\n",
       "         [-0.0797,  0.2471,  1.1300,  ...,  0.1505,  0.2354,  0.9576],\n",
       "         ...,\n",
       "         [ 1.1065,  0.6839,  1.2183,  ...,  0.3015, -0.1910, -0.1902],\n",
       "         [-0.3486, -0.7173, -0.3582,  ...,  0.4917,  0.7219,  0.1513],\n",
       "         [ 0.0119,  0.1017,  0.7839,  ..., -0.3752, -0.8127, -0.1257]],\n",
       "\n",
       "        [[ 0.3841,  1.1322,  0.1620,  ...,  0.7010,  0.0109,  0.6058],\n",
       "         [ 0.1664,  0.1873,  1.5924,  ...,  0.3733,  0.9096, -0.5399],\n",
       "         [ 0.4094, -0.0861, -0.7935,  ..., -0.1285, -0.9932, -0.3013],\n",
       "         ...,\n",
       "         [ 0.2688, -0.5630, -1.1902,  ...,  0.4493,  0.5404, -0.0103],\n",
       "         [ 0.0535,  0.4411,  0.5313,  ...,  0.0148, -1.0056,  0.3759],\n",
       "         [ 0.3031, -0.1590, -0.1316,  ..., -0.5384, -0.4271, -0.4876]],\n",
       "\n",
       "        [[-1.1865, -0.7280, -1.2331,  ..., -0.9013, -0.0542, -1.5949],\n",
       "         [-0.6345, -0.5920,  0.5326,  ..., -1.0395, -0.7963, -0.0647],\n",
       "         [-0.1132,  0.5166,  0.2569,  ...,  0.5595, -1.6881,  0.9485],\n",
       "         ...,\n",
       "         [-0.0254, -0.2669,  0.1927,  ..., -0.2917,  0.1088, -0.4807],\n",
       "         [-0.2609, -0.2328,  0.1404,  ..., -0.1325, -0.8436, -0.7524],\n",
       "         [-1.1399, -0.1751, -0.8705,  ...,  0.1589,  0.3377,  0.3493]]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a single conv2d layer\n",
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=10,\n",
    "                       kernel_size=3,\n",
    "                       stride=1,\n",
    "                       padding=0)\n",
    "\n",
    "# Pass the test_image through the conv layer\n",
    "conv_output = conv_layer(test_image)\n",
    "conv_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Stepping through `nn.MaxPool2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image oringal shape: torch.Size([3, 64, 64])\n",
      "Test image unsqueezed shape: torch.Size([1, 3, 64, 64])\n",
      "Shape after conv layer: torch.Size([1, 10, 62, 62])\n",
      "Shape after conv and max pool layers: torch.Size([1, 10, 31, 31])\n"
     ]
    }
   ],
   "source": [
    "# Print out original image shape withoug unsqueeze\n",
    "print(f\"Test image oringal shape: {test_image.shape}\")\n",
    "print(f\"Test image unsqueezed shape: {test_image.unsqueeze(0).shape}\")\n",
    "\n",
    "# Create a sample nn.MaxPool2d layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# Pass data through the conv layer\n",
    "test_image_conv = conv_layer(test_image.unsqueeze(0))\n",
    "print(f\"Shape after conv layer: {test_image_conv.shape}\")\n",
    "\n",
    "# Pass data through the max pool layer\n",
    "test_image_conv_max = max_pool_layer(test_image_conv)\n",
    "print(f\"Shape after conv and max pool layers: {test_image_conv_max.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor:\n",
      " tensor([[[[0.3367, 0.1288],\n",
      "          [0.2345, 0.2303]]]])\n",
      "Random tensor shape: torch.Size([1, 1, 2, 2])\n",
      "Max pool tensor: tensor([[[[0.3367]]]])\n",
      "Max pool tensor shape: torch.Size([1, 1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3367, 0.1288],\n",
       "          [0.2345, 0.2303]]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a random tensor with similar dimensions to the FashionMNIST dataset\n",
    "random_tensor = torch.randn(size=(1, 1, 2, 2))\n",
    "print(f\"Random tensor:\\n {random_tensor}\")\n",
    "print(f\"Random tensor shape: {random_tensor.shape}\")\n",
    "\n",
    "# Create a max pool layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# Pass the random tensor through the max pool layer\n",
    "max_pool_output = max_pool_layer(random_tensor)\n",
    "print(f\"Max pool tensor: {max_pool_output}\")\n",
    "print(f\"Max pool tensor shape: {max_pool_output.shape}\")\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Setup loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_block_1.0.weight',\n",
       "              tensor([[[[ 0.2548,  0.2767, -0.0781],\n",
       "                        [ 0.3062, -0.0730,  0.0673],\n",
       "                        [-0.1623,  0.1958,  0.2938]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2445,  0.2897,  0.0624],\n",
       "                        [ 0.2463,  0.0451,  0.1607],\n",
       "                        [-0.0471,  0.2570,  0.0493]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1556,  0.0850, -0.1536],\n",
       "                        [-0.0391, -0.1354,  0.2211],\n",
       "                        [-0.2631, -0.1537, -0.0941]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2004,  0.0315, -0.3292],\n",
       "                        [ 0.3010, -0.2832,  0.2573],\n",
       "                        [ 0.0555, -0.1082,  0.2060]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0520,  0.2693,  0.0364],\n",
       "                        [-0.1051,  0.0896, -0.0904],\n",
       "                        [ 0.1403,  0.2976,  0.1927]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1457,  0.1924,  0.0596],\n",
       "                        [ 0.1693, -0.2032, -0.3300],\n",
       "                        [-0.1288, -0.2557,  0.2735]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0960,  0.1381,  0.1054],\n",
       "                        [-0.0058,  0.2609, -0.2368],\n",
       "                        [ 0.0210, -0.2275,  0.1028]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1148,  0.1021, -0.0694],\n",
       "                        [ 0.2765, -0.1976, -0.1988],\n",
       "                        [-0.1988,  0.2998,  0.1111]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3208, -0.2751, -0.3306],\n",
       "                        [-0.2608, -0.2242,  0.1350],\n",
       "                        [ 0.1194,  0.2770, -0.1721]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2272,  0.1769, -0.1347],\n",
       "                        [ 0.2023, -0.0791,  0.1907],\n",
       "                        [-0.2590, -0.1682,  0.1016]]]], device='mps:0')),\n",
       "             ('conv_block_1.0.bias',\n",
       "              tensor([ 0.0705, -0.0850,  0.1987,  0.2266, -0.2417, -0.1780,  0.3052, -0.1125,\n",
       "                      -0.1182, -0.3225], device='mps:0')),\n",
       "             ('conv_block_1.2.weight',\n",
       "              tensor([[[[-0.0604,  0.0263, -0.0139],\n",
       "                        [-0.0765,  0.0025, -0.0720],\n",
       "                        [-0.0894, -0.0580, -0.0923]],\n",
       "              \n",
       "                       [[-0.0671,  0.1054,  0.0199],\n",
       "                        [ 0.0325, -0.0983, -0.0692],\n",
       "                        [-0.0351,  0.0165, -0.0928]],\n",
       "              \n",
       "                       [[-0.0454, -0.0631,  0.0003],\n",
       "                        [-0.0392, -0.0073, -0.0714],\n",
       "                        [-0.0724, -0.0615, -0.0361]],\n",
       "              \n",
       "                       [[-0.0832,  0.0884, -0.0209],\n",
       "                        [ 0.0907,  0.0328, -0.0893],\n",
       "                        [ 0.0729, -0.0290, -0.0404]],\n",
       "              \n",
       "                       [[-0.0875, -0.1048,  0.0302],\n",
       "                        [-0.0230,  0.0410, -0.0865],\n",
       "                        [ 0.0783, -0.0774, -0.0182]],\n",
       "              \n",
       "                       [[ 0.0220,  0.0544,  0.0851],\n",
       "                        [ 0.0960, -0.0836,  0.0265],\n",
       "                        [-0.0453, -0.0116, -0.0789]],\n",
       "              \n",
       "                       [[ 0.0960, -0.0774,  0.0563],\n",
       "                        [ 0.0370,  0.0343, -0.0570],\n",
       "                        [ 0.0958,  0.0232,  0.0136]],\n",
       "              \n",
       "                       [[-0.0929,  0.0442, -0.0158],\n",
       "                        [-0.0483,  0.0905,  0.0235],\n",
       "                        [-0.0583, -0.0534, -0.0050]],\n",
       "              \n",
       "                       [[ 0.0589, -0.0269, -0.0601],\n",
       "                        [-0.0361, -0.0787,  0.0376],\n",
       "                        [ 0.0816, -0.0992,  0.0245]],\n",
       "              \n",
       "                       [[ 0.0545,  0.0191, -0.0375],\n",
       "                        [ 0.0550,  0.0554,  0.0394],\n",
       "                        [-0.0185, -0.0279,  0.0113]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0186, -0.0314,  0.0674],\n",
       "                        [ 0.0906, -0.0104, -0.0236],\n",
       "                        [ 0.0015, -0.0063,  0.0253]],\n",
       "              \n",
       "                       [[ 0.0295, -0.0957, -0.0389],\n",
       "                        [ 0.0888,  0.0411, -0.0052],\n",
       "                        [-0.0636, -0.0645, -0.0944]],\n",
       "              \n",
       "                       [[-0.0344,  0.0356,  0.0672],\n",
       "                        [ 0.0487, -0.0932, -0.0634],\n",
       "                        [-0.0166,  0.1020,  0.0152]],\n",
       "              \n",
       "                       [[-0.0273,  0.0436, -0.0401],\n",
       "                        [-0.0682,  0.0769, -0.0479],\n",
       "                        [-0.0211, -0.1049,  0.0705]],\n",
       "              \n",
       "                       [[ 0.0799,  0.0384, -0.0735],\n",
       "                        [-0.1040, -0.0856,  0.0786],\n",
       "                        [ 0.0506,  0.0887,  0.0552]],\n",
       "              \n",
       "                       [[ 0.0267, -0.0010, -0.0802],\n",
       "                        [-0.0903, -0.0986,  0.0432],\n",
       "                        [-0.0518, -0.0212, -0.0607]],\n",
       "              \n",
       "                       [[-0.0192, -0.0742, -0.0689],\n",
       "                        [ 0.0350, -0.0313,  0.0651],\n",
       "                        [-0.0338, -0.0773, -0.0186]],\n",
       "              \n",
       "                       [[-0.0511, -0.0322, -0.1003],\n",
       "                        [ 0.0590, -0.0734,  0.0530],\n",
       "                        [ 0.0478,  0.0753, -0.0809]],\n",
       "              \n",
       "                       [[ 0.0758, -0.0498,  0.0391],\n",
       "                        [ 0.0990, -0.0149, -0.0008],\n",
       "                        [-0.0243, -0.0880,  0.0506]],\n",
       "              \n",
       "                       [[-0.1046,  0.0654,  0.0789],\n",
       "                        [ 0.0997, -0.0249, -0.0866],\n",
       "                        [ 0.0237,  0.0582, -0.1049]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0239, -0.0632, -0.0092],\n",
       "                        [-0.0519, -0.0431, -0.0335],\n",
       "                        [-0.1002,  0.0865,  0.0884]],\n",
       "              \n",
       "                       [[-0.0165, -0.0120, -0.0430],\n",
       "                        [-0.0952, -0.1026,  0.0392],\n",
       "                        [-0.0579, -0.0678, -0.0082]],\n",
       "              \n",
       "                       [[-0.0351, -0.0341,  0.0034],\n",
       "                        [-0.0224, -0.0363, -0.0505],\n",
       "                        [-0.0858,  0.0884, -0.0422]],\n",
       "              \n",
       "                       [[ 0.0279, -0.0366,  0.0086],\n",
       "                        [ 0.0983,  0.0486, -0.0913],\n",
       "                        [ 0.0418,  0.1001,  0.0277]],\n",
       "              \n",
       "                       [[ 0.0707,  0.1039, -0.0162],\n",
       "                        [ 0.0219, -0.0733, -0.0217],\n",
       "                        [ 0.0781,  0.0540, -0.0667]],\n",
       "              \n",
       "                       [[-0.0845, -0.0720, -0.1040],\n",
       "                        [-0.0813, -0.0261,  0.0711],\n",
       "                        [ 0.0176, -0.0802, -0.0846]],\n",
       "              \n",
       "                       [[ 0.0524, -0.0784, -0.0130],\n",
       "                        [ 0.0506, -0.0488, -0.0115],\n",
       "                        [-0.0092, -0.0249, -0.0534]],\n",
       "              \n",
       "                       [[-0.0940, -0.0852, -0.0564],\n",
       "                        [ 0.1018, -0.0509, -0.0708],\n",
       "                        [ 0.0256,  0.0291,  0.0578]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0587, -0.1045],\n",
       "                        [ 0.0093,  0.0639, -0.0097],\n",
       "                        [-0.0621,  0.1005, -0.0394]],\n",
       "              \n",
       "                       [[-0.0600, -0.0950,  0.0047],\n",
       "                        [ 0.0467,  0.0233,  0.0208],\n",
       "                        [-0.0799, -0.0984,  0.0019]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0961,  0.0608, -0.0614],\n",
       "                        [-0.0137, -0.0777, -0.0509],\n",
       "                        [ 0.0191,  0.0574,  0.0873]],\n",
       "              \n",
       "                       [[-0.0968,  0.0705, -0.0743],\n",
       "                        [ 0.0395,  0.0892,  0.0015],\n",
       "                        [ 0.0959, -0.0898, -0.0403]],\n",
       "              \n",
       "                       [[ 0.0615, -0.0230, -0.0216],\n",
       "                        [-0.0439,  0.0727,  0.0517],\n",
       "                        [ 0.0338, -0.0592, -0.0856]],\n",
       "              \n",
       "                       [[ 0.0114,  0.0312, -0.0487],\n",
       "                        [-0.0295,  0.0712,  0.0084],\n",
       "                        [ 0.0048, -0.0259, -0.0955]],\n",
       "              \n",
       "                       [[-0.0991, -0.0504, -0.0536],\n",
       "                        [ 0.0328, -0.0307, -0.0412],\n",
       "                        [ 0.1005,  0.0367,  0.0751]],\n",
       "              \n",
       "                       [[-0.0510, -0.0431,  0.0387],\n",
       "                        [-0.0702, -0.0689, -0.0051],\n",
       "                        [-0.0386, -0.0790,  0.0625]],\n",
       "              \n",
       "                       [[ 0.0848,  0.0171, -0.0184],\n",
       "                        [-0.0976, -0.0384,  0.0268],\n",
       "                        [ 0.0497, -0.0133, -0.0417]],\n",
       "              \n",
       "                       [[ 0.0587, -0.0839,  0.0666],\n",
       "                        [-0.0409,  0.0016, -0.0208],\n",
       "                        [ 0.0128, -0.0319,  0.0766]],\n",
       "              \n",
       "                       [[-0.0027,  0.0823,  0.1013],\n",
       "                        [-0.0514, -0.0769,  0.0846],\n",
       "                        [ 0.0826, -0.0805, -0.0081]],\n",
       "              \n",
       "                       [[-0.1039, -0.0863,  0.0204],\n",
       "                        [ 0.0280,  0.0223, -0.0287],\n",
       "                        [ 0.0972,  0.0151, -0.0622]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0060,  0.0253,  0.0369],\n",
       "                        [-0.0745,  0.0395, -0.0539],\n",
       "                        [-0.0876, -0.0576,  0.1017]],\n",
       "              \n",
       "                       [[ 0.0901,  0.0944,  0.0619],\n",
       "                        [ 0.0796, -0.0141, -0.0580],\n",
       "                        [ 0.0527, -0.0546, -0.0711]],\n",
       "              \n",
       "                       [[-0.0337,  0.0221,  0.0543],\n",
       "                        [-0.0409, -0.0620,  0.0142],\n",
       "                        [-0.0621, -0.0686,  0.0549]],\n",
       "              \n",
       "                       [[-0.0177,  0.0963,  0.1025],\n",
       "                        [ 0.0315,  0.0363,  0.0243],\n",
       "                        [ 0.0017, -0.0077,  0.0014]],\n",
       "              \n",
       "                       [[ 0.0394,  0.0980, -0.0273],\n",
       "                        [-0.0446, -0.0255, -0.0509],\n",
       "                        [ 0.0179,  0.0787,  0.0824]],\n",
       "              \n",
       "                       [[ 0.0484, -0.0776, -0.0566],\n",
       "                        [-0.0232, -0.0194,  0.0087],\n",
       "                        [-0.0968,  0.0328, -0.0804]],\n",
       "              \n",
       "                       [[-0.0667, -0.0876,  0.0918],\n",
       "                        [-0.0998,  0.0795, -0.0035],\n",
       "                        [-0.0123,  0.0659, -0.0097]],\n",
       "              \n",
       "                       [[ 0.0661,  0.0762, -0.0915],\n",
       "                        [ 0.0406,  0.0199,  0.0227],\n",
       "                        [ 0.0154,  0.0288, -0.0507]],\n",
       "              \n",
       "                       [[-0.0135,  0.1002,  0.0708],\n",
       "                        [-0.0040, -0.0991,  0.0046],\n",
       "                        [-0.0718,  0.0857, -0.0640]],\n",
       "              \n",
       "                       [[-0.0076, -0.0234,  0.0188],\n",
       "                        [ 0.0992,  0.0100,  0.0610],\n",
       "                        [ 0.0818,  0.0851, -0.0364]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0236,  0.0508, -0.0288],\n",
       "                        [ 0.0494, -0.0230, -0.0715],\n",
       "                        [ 0.0429,  0.0162,  0.0470]],\n",
       "              \n",
       "                       [[ 0.1047,  0.0720,  0.0999],\n",
       "                        [ 0.0056, -0.0907, -0.0739],\n",
       "                        [-0.0655, -0.0929, -0.0528]],\n",
       "              \n",
       "                       [[-0.0970, -0.0973, -0.0630],\n",
       "                        [-0.1039, -0.0647,  0.0402],\n",
       "                        [ 0.0879, -0.0314, -0.0307]],\n",
       "              \n",
       "                       [[ 0.0563, -0.0520, -0.0498],\n",
       "                        [ 0.0649, -0.0918,  0.0129],\n",
       "                        [ 0.0931,  0.0181,  0.0287]],\n",
       "              \n",
       "                       [[-0.0614, -0.0015,  0.0058],\n",
       "                        [ 0.0259,  0.0410,  0.0916],\n",
       "                        [-0.0805,  0.0032, -0.0527]],\n",
       "              \n",
       "                       [[-0.0834, -0.0084, -0.0928],\n",
       "                        [ 0.0736,  0.0122, -0.0568],\n",
       "                        [ 0.0551, -0.0998, -0.0408]],\n",
       "              \n",
       "                       [[-0.0205, -0.0896, -0.0670],\n",
       "                        [-0.0172,  0.0800,  0.1018],\n",
       "                        [ 0.0671, -0.0629, -0.0690]],\n",
       "              \n",
       "                       [[ 0.0920,  0.0373,  0.0028],\n",
       "                        [ 0.0143, -0.0847, -0.0352],\n",
       "                        [ 0.1015, -0.0260, -0.0053]],\n",
       "              \n",
       "                       [[-0.0875, -0.0590, -0.0022],\n",
       "                        [-0.0655, -0.0131,  0.0429],\n",
       "                        [-0.1031,  0.0313, -0.0697]],\n",
       "              \n",
       "                       [[-0.0514,  0.0405,  0.0838],\n",
       "                        [-0.0288, -0.0433, -0.0953],\n",
       "                        [-0.0544, -0.0923, -0.0241]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0215, -0.0988,  0.0920],\n",
       "                        [ 0.0661, -0.1032, -0.0503],\n",
       "                        [ 0.0344, -0.0217, -0.0115]],\n",
       "              \n",
       "                       [[-0.0476,  0.0847, -0.0589],\n",
       "                        [ 0.0874,  0.0068,  0.0212],\n",
       "                        [ 0.0822, -0.0174, -0.0600]],\n",
       "              \n",
       "                       [[-0.0170,  0.0855, -0.0782],\n",
       "                        [ 0.0239, -0.1036,  0.0553],\n",
       "                        [ 0.0389,  0.0045,  0.0452]],\n",
       "              \n",
       "                       [[ 0.0001,  0.0583, -0.0834],\n",
       "                        [-0.0155,  0.0468,  0.1050],\n",
       "                        [ 0.0537, -0.0767,  0.0811]],\n",
       "              \n",
       "                       [[-0.0235, -0.0225, -0.0958],\n",
       "                        [-0.0166,  0.0746,  0.0147],\n",
       "                        [-0.0614,  0.0324, -0.0338]],\n",
       "              \n",
       "                       [[ 0.0962, -0.0915, -0.0333],\n",
       "                        [-0.1018, -0.0415,  0.0332],\n",
       "                        [ 0.1015,  0.0177,  0.1033]],\n",
       "              \n",
       "                       [[ 0.0206,  0.0609,  0.0845],\n",
       "                        [ 0.0881, -0.0590,  0.0969],\n",
       "                        [ 0.0639, -0.0493, -0.0503]],\n",
       "              \n",
       "                       [[-0.0884,  0.0265, -0.0854],\n",
       "                        [ 0.0445,  0.0333, -0.0916],\n",
       "                        [ 0.0287, -0.0086,  0.0482]],\n",
       "              \n",
       "                       [[ 0.0605, -0.1048,  0.0967],\n",
       "                        [ 0.0884,  0.0419, -0.0963],\n",
       "                        [-0.0377, -0.0305, -0.0271]],\n",
       "              \n",
       "                       [[ 0.0594,  0.0383,  0.0835],\n",
       "                        [-0.0395,  0.0355,  0.0375],\n",
       "                        [-0.0878, -0.1022, -0.0547]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0722, -0.0992, -0.0918],\n",
       "                        [ 0.0591,  0.0569,  0.0867],\n",
       "                        [-0.0796, -0.0771,  0.0541]],\n",
       "              \n",
       "                       [[ 0.0917,  0.0631,  0.0165],\n",
       "                        [ 0.0347,  0.1000, -0.0680],\n",
       "                        [-0.0479,  0.0737, -0.0721]],\n",
       "              \n",
       "                       [[-0.0581,  0.0769,  0.0333],\n",
       "                        [ 0.0341, -0.0447, -0.0015],\n",
       "                        [ 0.0965, -0.0633,  0.0008]],\n",
       "              \n",
       "                       [[ 0.0501, -0.0728,  0.1024],\n",
       "                        [-0.0527, -0.0253, -0.0285],\n",
       "                        [-0.0687, -0.1034,  0.0594]],\n",
       "              \n",
       "                       [[ 0.0280, -0.0987, -0.0678],\n",
       "                        [ 0.1042,  0.0403,  0.0423],\n",
       "                        [-0.0631, -0.0462, -0.0159]],\n",
       "              \n",
       "                       [[-0.0193, -0.0722,  0.0087],\n",
       "                        [ 0.0105, -0.0133,  0.0146],\n",
       "                        [-0.0418,  0.0274,  0.0398]],\n",
       "              \n",
       "                       [[-0.0555, -0.1045,  0.0552],\n",
       "                        [ 0.0251, -0.0536,  0.1016],\n",
       "                        [-0.0477,  0.0712,  0.0535]],\n",
       "              \n",
       "                       [[-0.0884,  0.0680, -0.0969],\n",
       "                        [-0.0584, -0.0176, -0.0711],\n",
       "                        [ 0.1030, -0.0211,  0.0419]],\n",
       "              \n",
       "                       [[-0.0941,  0.0607, -0.0328],\n",
       "                        [-0.0802,  0.0154,  0.0511],\n",
       "                        [ 0.0912, -0.0644, -0.0519]],\n",
       "              \n",
       "                       [[ 0.0203,  0.0286,  0.0405],\n",
       "                        [ 0.0579, -0.0239,  0.0586],\n",
       "                        [ 0.0777, -0.0275,  0.0750]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0515,  0.0930, -0.0599],\n",
       "                        [-0.0521, -0.0305,  0.0053],\n",
       "                        [ 0.0633, -0.0602,  0.0528]],\n",
       "              \n",
       "                       [[-0.0378,  0.0637, -0.0050],\n",
       "                        [-0.0923, -0.0580, -0.0763],\n",
       "                        [ 0.0523, -0.0707, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0227, -0.0578,  0.0304],\n",
       "                        [-0.1029, -0.0754, -0.0955],\n",
       "                        [-0.0319, -0.0384,  0.0151]],\n",
       "              \n",
       "                       [[-0.0195,  0.0496,  0.0966],\n",
       "                        [ 0.0378, -0.0415, -0.0987],\n",
       "                        [ 0.0382, -0.0522,  0.0536]],\n",
       "              \n",
       "                       [[ 0.0705,  0.0407,  0.0989],\n",
       "                        [ 0.1001,  0.0223, -0.0768],\n",
       "                        [ 0.0942, -0.0500, -0.0498]],\n",
       "              \n",
       "                       [[ 0.0882,  0.0817,  0.0318],\n",
       "                        [ 0.0066, -0.0887, -0.0109],\n",
       "                        [ 0.1011,  0.0268,  0.0090]],\n",
       "              \n",
       "                       [[-0.0219, -0.0368,  0.0628],\n",
       "                        [ 0.0065,  0.0686, -0.0187],\n",
       "                        [ 0.0461,  0.0435,  0.0168]],\n",
       "              \n",
       "                       [[ 0.0662,  0.0661,  0.0977],\n",
       "                        [ 0.0810, -0.0270, -0.0892],\n",
       "                        [ 0.0193, -0.0009, -0.0275]],\n",
       "              \n",
       "                       [[-0.0177,  0.0050,  0.0769],\n",
       "                        [ 0.0329, -0.0374, -0.0433],\n",
       "                        [-0.0261, -0.0407,  0.0948]],\n",
       "              \n",
       "                       [[ 0.0558,  0.0952,  0.0003],\n",
       "                        [ 0.0213,  0.0366, -0.0998],\n",
       "                        [ 0.0094, -0.0071, -0.0591]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0818,  0.0933,  0.0857],\n",
       "                        [ 0.0489,  0.1006, -0.0428],\n",
       "                        [-0.0182,  0.0399, -0.0174]],\n",
       "              \n",
       "                       [[-0.0207, -0.0871,  0.0283],\n",
       "                        [-0.0637,  0.0038,  0.1028],\n",
       "                        [-0.0324, -0.0332,  0.0636]],\n",
       "              \n",
       "                       [[-0.0388, -0.0091,  0.0984],\n",
       "                        [-0.0432, -0.0754, -0.0590],\n",
       "                        [-0.0292, -0.0500, -0.0547]],\n",
       "              \n",
       "                       [[ 0.0426,  0.0179, -0.0337],\n",
       "                        [-0.0819, -0.0332, -0.0445],\n",
       "                        [-0.0343, -0.0951,  0.0227]],\n",
       "              \n",
       "                       [[-0.0774, -0.0821, -0.0861],\n",
       "                        [ 0.0440, -0.0635, -0.0435],\n",
       "                        [ 0.0826,  0.0560,  0.0604]],\n",
       "              \n",
       "                       [[-0.1001, -0.0756, -0.0398],\n",
       "                        [ 0.0871,  0.0108, -0.0788],\n",
       "                        [ 0.0007, -0.0819, -0.0231]],\n",
       "              \n",
       "                       [[-0.0290,  0.0912,  0.0326],\n",
       "                        [-0.0184,  0.0178, -0.0304],\n",
       "                        [ 0.0414,  0.0417,  0.0283]],\n",
       "              \n",
       "                       [[-0.0411,  0.0899, -0.0152],\n",
       "                        [-0.0410,  0.0660,  0.0859],\n",
       "                        [ 0.1049,  0.0312, -0.0359]],\n",
       "              \n",
       "                       [[ 0.0535,  0.0904, -0.1034],\n",
       "                        [-0.0131, -0.0719,  0.0196],\n",
       "                        [ 0.0436, -0.0218, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0474, -0.0177, -0.0885],\n",
       "                        [ 0.0843, -0.0531, -0.0116],\n",
       "                        [ 0.0099, -0.0063, -0.0992]]]], device='mps:0')),\n",
       "             ('conv_block_1.2.bias',\n",
       "              tensor([ 0.0484, -0.0479, -0.0547,  0.0252, -0.0550, -0.0487, -0.0355, -0.0396,\n",
       "                      -0.0440, -0.0284], device='mps:0')),\n",
       "             ('conv_block_2.0.weight',\n",
       "              tensor([[[[ 2.7393e-02, -8.5299e-02, -6.3802e-02],\n",
       "                        [ 1.5381e-03,  1.4659e-02,  5.8217e-02],\n",
       "                        [-7.4044e-02,  3.3646e-02,  5.9914e-02]],\n",
       "              \n",
       "                       [[ 5.8530e-02, -9.8180e-02, -4.0225e-02],\n",
       "                        [-9.0606e-02, -6.6704e-02,  5.8711e-02],\n",
       "                        [-1.5740e-02,  4.4769e-02, -6.1876e-02]],\n",
       "              \n",
       "                       [[ 1.6018e-02, -6.3758e-02,  5.2693e-02],\n",
       "                        [-4.6104e-02, -2.6432e-02, -9.1456e-02],\n",
       "                        [ 3.4822e-04,  1.0008e-01,  5.1163e-02]],\n",
       "              \n",
       "                       [[-5.6240e-02,  1.4176e-03, -1.1558e-02],\n",
       "                        [-8.4862e-02,  8.2650e-02,  1.6993e-03],\n",
       "                        [ 2.2199e-02, -4.2567e-02, -4.9323e-02]],\n",
       "              \n",
       "                       [[ 1.7381e-02,  3.8971e-02,  2.3643e-02],\n",
       "                        [-5.0801e-02,  1.0234e-01, -1.5517e-02],\n",
       "                        [-6.4554e-02, -4.9301e-02,  1.0377e-01]],\n",
       "              \n",
       "                       [[ 5.0766e-06, -1.4309e-02, -4.3867e-02],\n",
       "                        [-2.7633e-02, -8.8779e-02, -8.3767e-02],\n",
       "                        [ 6.1695e-02,  9.0172e-02,  1.0059e-01]],\n",
       "              \n",
       "                       [[-7.6099e-02,  5.7012e-02, -6.5245e-02],\n",
       "                        [ 6.2883e-02,  7.6058e-02,  8.1573e-02],\n",
       "                        [ 7.5900e-02,  6.5941e-02,  2.0516e-03]],\n",
       "              \n",
       "                       [[ 4.8434e-02, -3.7712e-02,  4.5899e-02],\n",
       "                        [-3.3879e-02, -1.7700e-03, -9.1746e-02],\n",
       "                        [-2.7562e-02, -5.5432e-02, -3.5557e-02]],\n",
       "              \n",
       "                       [[-6.7313e-02, -9.4810e-02,  6.8639e-03],\n",
       "                        [ 6.8408e-02,  9.6001e-02,  6.1512e-02],\n",
       "                        [-5.4638e-02, -1.0425e-01,  3.9983e-02]],\n",
       "              \n",
       "                       [[ 5.9062e-02, -9.0495e-02,  3.7798e-02],\n",
       "                        [ 8.9121e-02,  6.3853e-03, -6.3505e-02],\n",
       "                        [ 8.6423e-02,  4.5011e-02,  6.9802e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.1287e-02,  6.1342e-02, -7.2002e-02],\n",
       "                        [ 1.0430e-01, -4.4662e-02,  6.3516e-02],\n",
       "                        [ 2.1107e-02,  2.7935e-02, -1.6165e-02]],\n",
       "              \n",
       "                       [[ 4.3295e-02, -4.3932e-02, -9.9357e-02],\n",
       "                        [-4.0499e-02,  8.2592e-02, -2.7751e-02],\n",
       "                        [ 3.3132e-02, -3.8973e-02,  7.9073e-02]],\n",
       "              \n",
       "                       [[ 6.3086e-02,  3.7211e-02, -5.3881e-02],\n",
       "                        [-8.6133e-02,  3.9686e-03, -6.1839e-02],\n",
       "                        [ 8.6667e-02, -1.0130e-01,  4.7104e-02]],\n",
       "              \n",
       "                       [[ 1.0508e-01,  5.2792e-02,  3.5942e-02],\n",
       "                        [-1.0142e-01,  1.0139e-01, -1.8030e-02],\n",
       "                        [-9.8495e-02,  1.0406e-01, -4.2894e-02]],\n",
       "              \n",
       "                       [[-7.4575e-03,  9.6479e-02, -7.3070e-02],\n",
       "                        [-7.4576e-02,  1.7141e-02, -1.4109e-02],\n",
       "                        [ 2.4280e-02, -8.8407e-02,  3.1524e-03]],\n",
       "              \n",
       "                       [[-4.6882e-02, -5.1820e-02, -9.6517e-02],\n",
       "                        [ 5.5890e-02,  2.0306e-02, -8.9118e-02],\n",
       "                        [ 8.3648e-02,  3.1794e-02,  1.9560e-02]],\n",
       "              \n",
       "                       [[-6.1890e-02,  1.5896e-02,  1.0157e-01],\n",
       "                        [ 7.2299e-02, -8.2100e-02,  9.6220e-02],\n",
       "                        [ 8.1702e-03,  5.0698e-02,  8.1869e-02]],\n",
       "              \n",
       "                       [[ 8.9862e-02, -8.2170e-02,  9.2303e-02],\n",
       "                        [-7.1591e-02,  7.9021e-03, -7.3656e-02],\n",
       "                        [-2.3109e-02, -4.7901e-03, -1.2611e-02]],\n",
       "              \n",
       "                       [[-1.6652e-02,  8.3137e-03,  1.0398e-01],\n",
       "                        [ 6.1244e-02,  5.8973e-02,  4.2190e-02],\n",
       "                        [ 8.1606e-02, -4.8645e-03,  8.3813e-03]],\n",
       "              \n",
       "                       [[ 2.1693e-02, -9.1931e-02, -8.4913e-02],\n",
       "                        [ 1.2923e-02, -4.1241e-02, -1.9342e-03],\n",
       "                        [-2.4187e-02,  1.6408e-02,  6.8581e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4958e-02,  8.4418e-02,  8.3227e-02],\n",
       "                        [-8.0901e-02, -8.1400e-02, -8.5284e-02],\n",
       "                        [-5.7766e-02, -4.1033e-02, -7.9341e-03]],\n",
       "              \n",
       "                       [[-2.5635e-02, -5.3258e-02, -3.3488e-02],\n",
       "                        [-3.8131e-02,  1.0341e-01, -3.9068e-02],\n",
       "                        [-7.5473e-02,  4.3818e-02, -6.0886e-03]],\n",
       "              \n",
       "                       [[ 8.0698e-02,  6.5863e-02,  9.6843e-02],\n",
       "                        [-7.7197e-02,  6.7764e-02,  8.8464e-02],\n",
       "                        [-5.2054e-02,  9.6890e-02,  7.9019e-02]],\n",
       "              \n",
       "                       [[ 1.1544e-03,  5.0823e-02, -3.6853e-02],\n",
       "                        [-9.1936e-02,  2.6645e-02,  3.1425e-02],\n",
       "                        [-6.8891e-02,  5.1123e-02, -9.0043e-02]],\n",
       "              \n",
       "                       [[ 9.0718e-02,  1.0208e-01,  2.8699e-02],\n",
       "                        [-6.6137e-02,  5.1300e-02,  1.7963e-02],\n",
       "                        [ 2.8663e-02,  3.4643e-02,  8.0254e-02]],\n",
       "              \n",
       "                       [[-4.5309e-02, -2.3711e-02,  2.8746e-02],\n",
       "                        [ 1.1486e-02,  8.5000e-02, -5.5365e-02],\n",
       "                        [-3.8387e-03,  1.9696e-02, -2.7996e-02]],\n",
       "              \n",
       "                       [[ 7.1859e-02,  1.1530e-02, -9.7422e-02],\n",
       "                        [-1.1420e-02, -4.7809e-02,  1.0243e-02],\n",
       "                        [-1.2250e-02, -1.0456e-01, -1.9208e-02]],\n",
       "              \n",
       "                       [[-1.0096e-02, -3.1083e-02,  9.6848e-02],\n",
       "                        [-2.3000e-02,  6.7717e-02,  2.6112e-02],\n",
       "                        [-8.8979e-02,  2.4770e-02,  8.7356e-02]],\n",
       "              \n",
       "                       [[-6.8948e-02, -6.8134e-02,  1.0318e-01],\n",
       "                        [ 8.4697e-02, -5.8807e-02,  6.3429e-02],\n",
       "                        [-1.3485e-02, -1.0393e-01,  7.9198e-03]],\n",
       "              \n",
       "                       [[ 3.4057e-02, -3.1619e-02,  3.6670e-02],\n",
       "                        [-9.0136e-02,  7.3050e-02,  8.9865e-02],\n",
       "                        [ 5.8130e-02,  1.7866e-02,  3.4716e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.6269e-02, -2.6339e-02, -1.0063e-02],\n",
       "                        [-5.8659e-02, -7.7857e-02,  7.0900e-02],\n",
       "                        [ 7.1535e-02, -9.5731e-02,  3.3542e-02]],\n",
       "              \n",
       "                       [[ 4.2881e-02,  1.0014e-01,  6.0985e-02],\n",
       "                        [ 9.6907e-02, -3.4510e-02,  7.3827e-02],\n",
       "                        [ 8.5740e-02, -9.9541e-02, -8.4613e-02]],\n",
       "              \n",
       "                       [[ 2.1335e-02,  5.7557e-02, -5.2369e-02],\n",
       "                        [ 1.1609e-02, -1.5303e-04,  2.6680e-02],\n",
       "                        [-5.6642e-02,  5.9455e-02,  7.0098e-02]],\n",
       "              \n",
       "                       [[-7.3139e-02,  1.0211e-03,  2.9247e-04],\n",
       "                        [ 3.3849e-02,  9.8198e-02,  3.0913e-02],\n",
       "                        [-2.3951e-02,  9.4672e-02, -4.0112e-02]],\n",
       "              \n",
       "                       [[-3.0608e-02,  7.1969e-03, -8.0270e-02],\n",
       "                        [ 1.1470e-02, -7.1518e-02,  1.0838e-02],\n",
       "                        [ 1.0099e-02,  1.4591e-02, -8.8891e-02]],\n",
       "              \n",
       "                       [[-1.0012e-01,  4.8501e-02,  9.0399e-02],\n",
       "                        [-9.3537e-02,  3.9043e-02, -7.7594e-02],\n",
       "                        [ 6.6082e-03,  9.8068e-02,  7.9965e-02]],\n",
       "              \n",
       "                       [[-7.7069e-02,  6.5203e-02,  5.5057e-02],\n",
       "                        [-1.6168e-04,  1.0211e-01, -4.1866e-02],\n",
       "                        [-2.4530e-02, -5.3275e-02,  1.5168e-02]],\n",
       "              \n",
       "                       [[ 2.7911e-02,  8.3990e-03, -5.9307e-02],\n",
       "                        [-4.7452e-02,  3.5855e-02, -9.2426e-02],\n",
       "                        [-1.6416e-02, -2.3350e-03, -4.2708e-02]],\n",
       "              \n",
       "                       [[ 3.8360e-02,  6.7940e-03,  7.4004e-02],\n",
       "                        [-9.3616e-03, -6.6528e-02,  7.4477e-02],\n",
       "                        [ 1.4720e-02, -3.0189e-02, -6.9476e-02]],\n",
       "              \n",
       "                       [[ 2.4707e-02, -1.0053e-01,  2.7762e-02],\n",
       "                        [ 5.2119e-02, -9.2465e-02, -6.9009e-02],\n",
       "                        [-7.5781e-02,  8.8597e-02,  8.9611e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.5987e-03,  9.8959e-02, -3.5239e-02],\n",
       "                        [-1.0233e-01,  3.6819e-02,  3.7343e-02],\n",
       "                        [ 1.0334e-01, -3.0510e-05,  8.0785e-02]],\n",
       "              \n",
       "                       [[ 6.4612e-02,  7.6292e-02, -1.0460e-01],\n",
       "                        [ 8.6800e-02, -8.9856e-02,  9.4501e-02],\n",
       "                        [-4.3682e-03, -9.3415e-02,  2.9314e-02]],\n",
       "              \n",
       "                       [[-2.1456e-02, -9.4678e-02, -3.8215e-02],\n",
       "                        [ 1.0868e-02,  8.2098e-02, -3.2406e-02],\n",
       "                        [ 6.2610e-02,  1.3200e-02,  3.5531e-03]],\n",
       "              \n",
       "                       [[ 2.0170e-02, -6.9177e-02, -8.7616e-02],\n",
       "                        [-3.3121e-02, -9.8226e-02, -4.9158e-02],\n",
       "                        [ 4.8494e-03, -6.9424e-02, -4.3723e-02]],\n",
       "              \n",
       "                       [[-1.8941e-02, -1.2144e-02, -5.8187e-02],\n",
       "                        [ 5.0650e-03, -1.4795e-02,  3.0147e-02],\n",
       "                        [ 4.7611e-03, -5.2638e-02, -3.6291e-02]],\n",
       "              \n",
       "                       [[-1.2149e-03, -6.5774e-02,  8.2520e-03],\n",
       "                        [-7.4425e-03,  4.0897e-02,  2.4947e-02],\n",
       "                        [ 7.8887e-02, -3.4749e-03, -7.7887e-02]],\n",
       "              \n",
       "                       [[ 4.7119e-02, -7.1240e-02, -1.4489e-02],\n",
       "                        [-3.4132e-02, -3.9997e-02, -3.9000e-02],\n",
       "                        [ 9.6863e-02,  6.0342e-02,  2.9213e-02]],\n",
       "              \n",
       "                       [[ 9.8975e-02, -9.5524e-02,  1.7010e-02],\n",
       "                        [ 6.7481e-02,  7.0022e-02, -8.3890e-02],\n",
       "                        [ 3.7514e-02, -6.0050e-02, -4.1187e-03]],\n",
       "              \n",
       "                       [[-2.1996e-02, -8.8013e-02, -1.0055e-01],\n",
       "                        [-6.9349e-02,  4.7832e-02,  4.8218e-02],\n",
       "                        [-9.1681e-02, -3.9586e-02,  1.7218e-03]],\n",
       "              \n",
       "                       [[-9.1135e-02,  5.9393e-02,  9.5473e-02],\n",
       "                        [ 1.8643e-02, -7.8321e-02,  2.4580e-02],\n",
       "                        [ 3.8265e-02,  8.3468e-02, -5.6085e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.4437e-02,  4.6312e-02,  6.5624e-03],\n",
       "                        [-3.4345e-02, -4.4169e-02, -5.4351e-02],\n",
       "                        [ 8.5328e-02, -1.8187e-02,  7.6022e-02]],\n",
       "              \n",
       "                       [[ 9.4094e-02,  1.3353e-02,  2.2454e-02],\n",
       "                        [-7.1789e-03,  7.2397e-02, -9.4983e-02],\n",
       "                        [ 4.1919e-02, -1.7174e-02,  4.8132e-02]],\n",
       "              \n",
       "                       [[-4.6949e-04, -3.9029e-02, -1.1379e-02],\n",
       "                        [ 5.6920e-02, -7.3210e-02, -6.6629e-02],\n",
       "                        [-2.3611e-02, -3.8235e-02,  4.1409e-02]],\n",
       "              \n",
       "                       [[ 7.0937e-02, -1.1289e-02,  9.9672e-02],\n",
       "                        [-4.4042e-02, -5.9151e-02, -4.7191e-02],\n",
       "                        [-7.2624e-02, -7.3885e-02, -9.3921e-02]],\n",
       "              \n",
       "                       [[-9.3422e-02,  2.7512e-02,  6.4284e-02],\n",
       "                        [ 9.8963e-02,  8.9787e-02, -6.0709e-03],\n",
       "                        [ 2.0454e-02, -6.3068e-02,  4.0743e-02]],\n",
       "              \n",
       "                       [[-1.0107e-01,  4.9719e-02,  1.9334e-02],\n",
       "                        [ 3.2393e-02,  3.8595e-02, -4.8394e-02],\n",
       "                        [ 9.0452e-02,  5.0307e-02,  6.9243e-02]],\n",
       "              \n",
       "                       [[ 1.3922e-02,  6.6196e-02,  7.0941e-02],\n",
       "                        [ 4.7775e-02,  8.0297e-02, -1.9119e-02],\n",
       "                        [ 6.9310e-02,  2.4286e-02,  6.3424e-02]],\n",
       "              \n",
       "                       [[ 1.0267e-01,  2.3869e-02, -3.9124e-02],\n",
       "                        [-1.0488e-02,  2.9676e-02,  1.7773e-02],\n",
       "                        [-2.8795e-02,  8.2590e-02,  6.3331e-02]],\n",
       "              \n",
       "                       [[-6.5475e-02, -8.5889e-03, -1.0119e-02],\n",
       "                        [-6.6063e-02,  1.5374e-02, -3.2360e-02],\n",
       "                        [-5.4419e-02, -3.3894e-02, -3.7584e-02]],\n",
       "              \n",
       "                       [[ 1.0084e-01,  4.0432e-02,  1.0373e-01],\n",
       "                        [ 2.8903e-02,  2.3868e-02,  4.3333e-02],\n",
       "                        [ 1.8092e-02, -8.2722e-02, -6.2334e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5538e-02,  1.5846e-03,  3.9709e-02],\n",
       "                        [ 4.0588e-02,  8.3623e-02,  2.1458e-02],\n",
       "                        [-3.5975e-02, -7.9271e-02, -7.7203e-02]],\n",
       "              \n",
       "                       [[-6.2965e-02,  3.1792e-02,  5.6950e-02],\n",
       "                        [ 9.2224e-02, -3.3342e-02, -8.3150e-03],\n",
       "                        [-3.1303e-02, -3.8517e-04,  3.3837e-02]],\n",
       "              \n",
       "                       [[-2.3160e-03,  4.8799e-03,  1.3354e-02],\n",
       "                        [ 3.9256e-02, -3.1981e-02, -6.2855e-02],\n",
       "                        [ 2.4869e-02, -1.2481e-02, -4.7753e-02]],\n",
       "              \n",
       "                       [[ 4.4268e-02,  9.5597e-04, -1.5333e-02],\n",
       "                        [-5.1027e-02, -1.3868e-02, -8.9632e-02],\n",
       "                        [ 2.3980e-02,  1.5818e-03,  6.3966e-02]],\n",
       "              \n",
       "                       [[ 6.8063e-03,  8.4277e-03,  2.8715e-02],\n",
       "                        [ 8.0210e-02, -4.9812e-02,  6.2930e-02],\n",
       "                        [ 2.5779e-02, -7.0320e-02,  3.6702e-02]],\n",
       "              \n",
       "                       [[-6.3217e-02, -3.3181e-02, -5.0245e-02],\n",
       "                        [-7.1711e-02,  8.3017e-02, -9.4217e-02],\n",
       "                        [ 5.2706e-02, -9.4870e-02, -1.2829e-02]],\n",
       "              \n",
       "                       [[ 6.2868e-03,  7.4937e-02, -3.8147e-02],\n",
       "                        [ 3.0340e-02,  1.6329e-02,  6.2021e-02],\n",
       "                        [ 6.2667e-03,  3.9470e-02, -6.3677e-02]],\n",
       "              \n",
       "                       [[-7.3250e-02,  9.3928e-02, -7.6808e-02],\n",
       "                        [-1.7945e-02, -1.2742e-02,  1.0308e-01],\n",
       "                        [-2.2780e-02, -8.0249e-02, -2.6721e-02]],\n",
       "              \n",
       "                       [[ 5.4372e-02,  4.1773e-02,  8.7204e-02],\n",
       "                        [-2.1579e-02,  4.9653e-02, -9.9194e-02],\n",
       "                        [ 4.0787e-02,  4.8432e-02,  6.7998e-02]],\n",
       "              \n",
       "                       [[-6.0446e-02, -2.8142e-02,  2.5502e-02],\n",
       "                        [-7.4905e-02, -8.3851e-02, -1.0141e-01],\n",
       "                        [ 5.8842e-03,  6.5458e-02,  2.7075e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.4263e-03,  3.6727e-02, -6.6240e-02],\n",
       "                        [ 1.1113e-02, -2.6186e-02, -5.2193e-02],\n",
       "                        [ 9.0902e-02, -8.1550e-02,  1.5448e-02]],\n",
       "              \n",
       "                       [[-9.2624e-02, -3.5762e-03, -4.6840e-02],\n",
       "                        [ 3.4695e-02, -5.9191e-02,  6.7466e-02],\n",
       "                        [-8.5536e-02,  6.3313e-02, -7.9181e-02]],\n",
       "              \n",
       "                       [[ 5.6456e-02, -4.4384e-02, -2.4556e-04],\n",
       "                        [-1.9238e-02,  6.8414e-02,  3.4546e-02],\n",
       "                        [-9.2887e-02,  9.6914e-03, -7.2718e-02]],\n",
       "              \n",
       "                       [[ 7.8800e-02,  1.7319e-02, -2.7109e-02],\n",
       "                        [-5.3777e-02,  3.6485e-02, -6.3129e-02],\n",
       "                        [ 4.9992e-02,  5.7519e-02,  6.4701e-02]],\n",
       "              \n",
       "                       [[ 2.7537e-02, -9.2272e-02,  7.5823e-02],\n",
       "                        [-3.2700e-02, -3.1163e-02, -1.1325e-02],\n",
       "                        [ 7.7068e-02,  8.1052e-02,  1.6276e-02]],\n",
       "              \n",
       "                       [[ 5.0296e-02, -9.8241e-02,  2.4900e-04],\n",
       "                        [-9.3254e-02,  3.5876e-02, -7.5099e-02],\n",
       "                        [-3.7568e-02,  7.3684e-02,  1.0074e-01]],\n",
       "              \n",
       "                       [[-6.3286e-02, -5.8503e-02,  1.3055e-02],\n",
       "                        [ 4.1437e-02, -1.7168e-02, -3.2918e-02],\n",
       "                        [-6.9237e-02,  4.4997e-02,  1.0328e-01]],\n",
       "              \n",
       "                       [[-5.1026e-02,  4.9718e-02,  5.1481e-02],\n",
       "                        [ 8.4728e-02, -1.2001e-02,  3.3202e-03],\n",
       "                        [ 7.7444e-02,  6.6631e-02,  1.0411e-01]],\n",
       "              \n",
       "                       [[-3.0207e-02,  4.1709e-02,  7.3605e-02],\n",
       "                        [-7.1553e-02,  2.0940e-02, -2.3586e-02],\n",
       "                        [ 6.7760e-02, -4.7342e-02,  7.3933e-03]],\n",
       "              \n",
       "                       [[ 6.3067e-02, -9.6567e-02, -8.9004e-02],\n",
       "                        [-5.3989e-02,  6.7611e-02,  7.0680e-02],\n",
       "                        [-7.1991e-02,  2.0100e-02, -5.5854e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8926e-02,  9.0907e-02,  5.0914e-02],\n",
       "                        [-2.8828e-02,  1.5516e-02,  2.0424e-02],\n",
       "                        [ 2.4691e-02, -3.6079e-02, -6.2074e-02]],\n",
       "              \n",
       "                       [[ 6.9788e-02,  1.4164e-02,  4.4119e-02],\n",
       "                        [-3.9922e-02,  5.1057e-02,  7.6713e-02],\n",
       "                        [ 6.4107e-02,  2.8660e-02,  1.0371e-01]],\n",
       "              \n",
       "                       [[-2.3053e-04,  2.2441e-02,  1.0015e-01],\n",
       "                        [ 1.0245e-01, -4.4506e-02,  9.4953e-02],\n",
       "                        [ 3.8902e-02, -1.1799e-02,  9.2038e-02]],\n",
       "              \n",
       "                       [[-5.4605e-02,  6.8490e-02,  1.0445e-01],\n",
       "                        [-7.2701e-02, -6.2201e-02, -1.0445e-01],\n",
       "                        [-1.8970e-02, -9.5733e-02, -3.5304e-02]],\n",
       "              \n",
       "                       [[ 3.2002e-02,  7.4511e-02,  5.8717e-02],\n",
       "                        [ 5.8511e-02,  4.3730e-02, -6.5378e-02],\n",
       "                        [-8.3694e-02,  4.3696e-03,  1.0009e-01]],\n",
       "              \n",
       "                       [[ 5.9351e-03, -9.0662e-03, -7.1545e-02],\n",
       "                        [-5.2266e-02, -8.1256e-02,  8.4398e-02],\n",
       "                        [-1.7174e-02, -9.3119e-02,  1.1308e-02]],\n",
       "              \n",
       "                       [[ 7.6494e-03, -1.3023e-02,  3.7733e-02],\n",
       "                        [ 5.6687e-02, -9.9128e-02, -8.0753e-02],\n",
       "                        [-5.0639e-03, -9.7729e-02, -9.5750e-02]],\n",
       "              \n",
       "                       [[ 9.3067e-02, -8.0174e-03, -5.2113e-02],\n",
       "                        [-3.6157e-02, -8.2295e-02,  8.2258e-02],\n",
       "                        [-2.2857e-02, -5.9265e-02, -7.9944e-02]],\n",
       "              \n",
       "                       [[ 6.1611e-02, -1.4571e-02, -1.1074e-02],\n",
       "                        [-2.7473e-02, -5.0883e-02,  1.8751e-02],\n",
       "                        [ 8.1099e-02, -6.1093e-02,  5.0504e-03]],\n",
       "              \n",
       "                       [[-8.0165e-02, -4.9426e-02,  9.2525e-02],\n",
       "                        [ 1.1052e-03,  1.0154e-01, -1.8468e-02],\n",
       "                        [-5.7453e-02, -6.2981e-02,  9.3426e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.1058e-02,  5.5318e-02,  2.6203e-02],\n",
       "                        [ 3.1107e-02,  5.9476e-02, -2.7577e-02],\n",
       "                        [ 6.5223e-02, -8.3982e-02, -3.7087e-02]],\n",
       "              \n",
       "                       [[ 7.7164e-02,  3.1283e-02, -1.4038e-02],\n",
       "                        [-2.4616e-02, -6.4364e-02,  6.4098e-02],\n",
       "                        [-3.3520e-03, -3.5664e-03,  2.4929e-02]],\n",
       "              \n",
       "                       [[ 7.7787e-02, -5.3778e-02, -3.6303e-02],\n",
       "                        [ 7.1429e-02,  5.9532e-02, -5.1855e-02],\n",
       "                        [-1.0428e-01,  1.9555e-02,  5.5434e-02]],\n",
       "              \n",
       "                       [[ 2.5178e-02,  7.4768e-02, -8.3640e-02],\n",
       "                        [ 5.3156e-02, -6.5531e-02,  5.9325e-02],\n",
       "                        [ 7.8394e-02,  3.3385e-02,  8.5284e-02]],\n",
       "              \n",
       "                       [[-6.9481e-02, -9.4275e-02, -1.0135e-01],\n",
       "                        [ 6.6179e-02,  3.6926e-02, -7.7188e-02],\n",
       "                        [ 5.1048e-02,  9.6177e-02, -1.0394e-01]],\n",
       "              \n",
       "                       [[ 7.6466e-02,  1.6167e-02,  9.8053e-03],\n",
       "                        [ 9.4847e-02,  9.5458e-02,  4.4414e-02],\n",
       "                        [ 8.3288e-02,  4.3853e-02,  1.7176e-02]],\n",
       "              \n",
       "                       [[-9.2656e-02,  1.9689e-02, -7.4993e-02],\n",
       "                        [ 3.2452e-02,  1.8598e-02,  2.3681e-03],\n",
       "                        [-7.2071e-02, -6.3899e-02,  7.7912e-02]],\n",
       "              \n",
       "                       [[ 5.1336e-02,  5.5576e-02, -3.1410e-02],\n",
       "                        [-1.8151e-02, -2.7014e-02,  7.2489e-02],\n",
       "                        [-4.5504e-02,  6.6394e-02,  7.2679e-02]],\n",
       "              \n",
       "                       [[-9.6403e-02,  6.4369e-04, -2.0076e-02],\n",
       "                        [-5.8273e-02,  4.5507e-02, -1.2807e-02],\n",
       "                        [ 9.2287e-02, -6.5976e-02,  4.8976e-02]],\n",
       "              \n",
       "                       [[-8.9998e-02, -5.2833e-02,  7.1903e-03],\n",
       "                        [ 8.3283e-02,  5.5521e-02, -8.6550e-02],\n",
       "                        [ 1.1676e-02, -6.2138e-02,  4.5674e-03]]]], device='mps:0')),\n",
       "             ('conv_block_2.0.bias',\n",
       "              tensor([-0.0878, -0.0309,  0.0723, -0.0967, -0.1005,  0.0192,  0.0144, -0.0193,\n",
       "                       0.0920, -0.0635], device='mps:0')),\n",
       "             ('conv_block_2.2.weight',\n",
       "              tensor([[[[-6.3992e-02, -7.8791e-02, -1.9619e-02],\n",
       "                        [-2.6901e-02,  6.5222e-02, -5.9186e-03],\n",
       "                        [ 3.3663e-02, -4.3804e-02,  8.5507e-02]],\n",
       "              \n",
       "                       [[ 8.8862e-02, -9.4401e-02, -2.7090e-02],\n",
       "                        [-8.9439e-02,  4.4781e-02, -9.2094e-02],\n",
       "                        [-4.9839e-02,  1.0532e-01, -1.0066e-01]],\n",
       "              \n",
       "                       [[ 7.7771e-02,  8.9049e-03,  8.4289e-02],\n",
       "                        [-5.3494e-02,  6.9236e-02,  1.2718e-02],\n",
       "                        [ 8.1073e-03,  7.1945e-02, -1.0019e-01]],\n",
       "              \n",
       "                       [[-8.4902e-02,  1.0180e-01, -6.3298e-02],\n",
       "                        [-7.5980e-02, -5.1539e-03, -3.3742e-02],\n",
       "                        [-1.4421e-02, -7.0623e-02,  3.8034e-02]],\n",
       "              \n",
       "                       [[-9.0703e-02,  8.5374e-03,  6.1510e-02],\n",
       "                        [ 2.0253e-02,  1.4006e-02,  1.5418e-02],\n",
       "                        [-3.0880e-02, -2.0080e-02, -4.4450e-02]],\n",
       "              \n",
       "                       [[-7.1207e-02, -5.5810e-02,  1.0420e-01],\n",
       "                        [-1.7641e-02,  3.6924e-02,  7.2896e-02],\n",
       "                        [-8.2343e-03, -5.6707e-02, -7.1419e-02]],\n",
       "              \n",
       "                       [[-3.8833e-02,  3.7624e-02, -8.8771e-02],\n",
       "                        [-1.2870e-02,  4.0096e-02,  8.5999e-02],\n",
       "                        [ 3.1721e-02,  2.0846e-02,  7.2162e-02]],\n",
       "              \n",
       "                       [[ 4.8708e-02,  3.5661e-02, -3.2682e-02],\n",
       "                        [-8.4528e-02, -2.2769e-02, -1.9117e-02],\n",
       "                        [ 7.7410e-03, -1.1593e-02,  4.2616e-02]],\n",
       "              \n",
       "                       [[ 7.0050e-02, -4.2735e-02, -1.0002e-01],\n",
       "                        [-5.4081e-02, -5.0436e-02,  5.9750e-02],\n",
       "                        [-6.7994e-02, -9.9145e-03, -2.2340e-02]],\n",
       "              \n",
       "                       [[-6.3976e-02,  4.7780e-02, -4.3909e-02],\n",
       "                        [-5.4531e-03, -7.4112e-02, -1.0632e-02],\n",
       "                        [ 1.4977e-02, -4.2894e-03, -3.9386e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.1315e-02, -2.7311e-02, -5.8439e-02],\n",
       "                        [-7.7732e-02, -2.2329e-02, -9.9578e-02],\n",
       "                        [ 8.7492e-02, -5.0357e-02, -4.3684e-02]],\n",
       "              \n",
       "                       [[ 9.7439e-03,  2.7326e-02, -9.9393e-03],\n",
       "                        [ 7.2313e-02, -6.1448e-02,  3.7777e-02],\n",
       "                        [-2.3773e-04, -8.5747e-02, -4.0824e-02]],\n",
       "              \n",
       "                       [[ 2.6825e-02,  2.0138e-02,  7.6647e-02],\n",
       "                        [ 7.0518e-02, -5.7493e-02, -4.5013e-02],\n",
       "                        [-2.2351e-02, -7.5517e-02, -2.8459e-02]],\n",
       "              \n",
       "                       [[-8.6258e-02,  4.0092e-02,  7.4583e-02],\n",
       "                        [ 8.3459e-03, -7.5460e-02, -7.9827e-02],\n",
       "                        [-4.1036e-02,  3.0659e-02,  2.5711e-03]],\n",
       "              \n",
       "                       [[ 1.9166e-02,  9.9346e-02,  4.8956e-02],\n",
       "                        [ 2.2665e-02, -2.1327e-02,  4.9864e-02],\n",
       "                        [ 3.8563e-02, -9.4879e-02, -6.2266e-02]],\n",
       "              \n",
       "                       [[ 3.5381e-03,  3.9997e-02,  5.1282e-02],\n",
       "                        [-6.2748e-02, -1.0458e-01, -5.4909e-03],\n",
       "                        [-1.2050e-02,  3.0588e-02, -2.8988e-02]],\n",
       "              \n",
       "                       [[ 8.0588e-02,  7.0333e-03,  7.6975e-02],\n",
       "                        [-7.3398e-02,  4.2167e-02,  1.2560e-02],\n",
       "                        [-5.2720e-02,  5.2256e-02, -1.0372e-01]],\n",
       "              \n",
       "                       [[ 8.5220e-02,  8.4947e-03,  1.0178e-02],\n",
       "                        [ 4.8746e-02,  8.7503e-03,  4.5184e-02],\n",
       "                        [ 6.7063e-02, -8.2268e-02,  6.9735e-02]],\n",
       "              \n",
       "                       [[-1.5784e-02, -2.4513e-02,  2.1217e-02],\n",
       "                        [ 8.2446e-02, -5.7302e-02, -7.1039e-02],\n",
       "                        [ 6.5418e-02, -4.9507e-02,  3.3937e-02]],\n",
       "              \n",
       "                       [[-1.5530e-02,  2.9014e-02,  8.0439e-02],\n",
       "                        [-5.3421e-02, -5.1151e-02,  5.1716e-02],\n",
       "                        [ 5.7714e-03, -1.1601e-02, -9.2590e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.9309e-02, -3.9919e-03, -1.9415e-02],\n",
       "                        [-4.3269e-02, -2.0801e-02,  5.1233e-02],\n",
       "                        [-2.4227e-03,  9.0147e-02, -6.0858e-03]],\n",
       "              \n",
       "                       [[-1.5122e-02,  5.9498e-02, -2.7275e-03],\n",
       "                        [-2.1039e-02,  3.5231e-02,  8.3129e-02],\n",
       "                        [ 2.6305e-02,  7.3398e-02,  6.8309e-02]],\n",
       "              \n",
       "                       [[ 2.9810e-02,  3.6650e-02,  3.4014e-02],\n",
       "                        [ 1.0934e-02,  8.9675e-02,  9.7308e-02],\n",
       "                        [ 3.7524e-02, -5.2640e-03,  9.4509e-02]],\n",
       "              \n",
       "                       [[-8.2042e-02,  7.7453e-02,  5.5849e-02],\n",
       "                        [ 6.7687e-02, -8.0992e-03, -7.8646e-02],\n",
       "                        [ 7.5193e-02, -4.6091e-02,  2.7734e-02]],\n",
       "              \n",
       "                       [[ 5.9719e-02, -9.8508e-02,  6.9954e-03],\n",
       "                        [-3.7444e-02,  7.4815e-02, -6.7114e-02],\n",
       "                        [ 6.4001e-02,  6.5730e-02,  5.8156e-02]],\n",
       "              \n",
       "                       [[ 1.0119e-01,  1.5964e-02, -9.5541e-02],\n",
       "                        [ 7.5248e-02,  9.6499e-03,  2.0918e-03],\n",
       "                        [-1.0041e-01, -2.3691e-02, -5.1162e-02]],\n",
       "              \n",
       "                       [[ 1.0324e-01,  7.5054e-02,  7.8634e-02],\n",
       "                        [ 7.2188e-02, -6.5340e-02, -4.5270e-02],\n",
       "                        [-4.1252e-02, -4.2257e-02,  8.2054e-02]],\n",
       "              \n",
       "                       [[ 3.5815e-02,  8.4470e-02, -4.9309e-03],\n",
       "                        [-9.3965e-02, -3.0582e-02,  7.4081e-02],\n",
       "                        [ 6.4174e-02,  3.2632e-02, -3.0919e-02]],\n",
       "              \n",
       "                       [[-9.8386e-02, -5.6639e-02,  5.4958e-02],\n",
       "                        [-4.2518e-02,  5.0421e-02,  2.8781e-02],\n",
       "                        [-4.0486e-02,  6.4202e-02, -3.3871e-02]],\n",
       "              \n",
       "                       [[-3.5020e-03, -4.0152e-02, -9.9988e-02],\n",
       "                        [ 1.6996e-02,  3.0460e-02, -5.3072e-02],\n",
       "                        [ 6.4663e-02, -9.4558e-02, -1.0161e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.5106e-02, -3.6430e-02, -1.1707e-02],\n",
       "                        [-2.0370e-02,  4.8108e-02, -9.2510e-02],\n",
       "                        [ 1.5521e-02,  1.8254e-03,  2.7842e-02]],\n",
       "              \n",
       "                       [[ 1.0479e-01,  6.4874e-02, -5.8366e-02],\n",
       "                        [-8.6378e-02, -2.5520e-02, -5.2876e-02],\n",
       "                        [ 3.6820e-02,  9.6628e-04,  8.4783e-02]],\n",
       "              \n",
       "                       [[ 4.1405e-02, -1.9382e-02,  3.6229e-03],\n",
       "                        [ 2.5244e-02, -1.3080e-02,  8.5058e-02],\n",
       "                        [-8.2420e-02,  5.1377e-02, -6.7192e-02]],\n",
       "              \n",
       "                       [[-9.2347e-02, -2.1640e-02,  5.1366e-02],\n",
       "                        [ 7.4478e-02,  2.6452e-02, -9.1104e-03],\n",
       "                        [-5.9092e-03, -4.2731e-02, -9.4592e-03]],\n",
       "              \n",
       "                       [[-7.2831e-03,  8.9699e-02,  6.1690e-02],\n",
       "                        [-8.4351e-02,  4.3604e-04, -6.4834e-02],\n",
       "                        [-1.6733e-02, -8.3776e-02,  2.7402e-02]],\n",
       "              \n",
       "                       [[-7.6008e-02,  1.0406e-01,  7.9605e-02],\n",
       "                        [-7.2559e-02, -9.9239e-02,  4.1128e-03],\n",
       "                        [-2.9425e-02,  3.0945e-02, -7.1353e-02]],\n",
       "              \n",
       "                       [[ 4.3148e-02, -9.1047e-02, -5.5632e-02],\n",
       "                        [-5.5414e-02,  5.1007e-02, -2.7597e-03],\n",
       "                        [-1.0130e-01, -6.0201e-02, -4.8781e-02]],\n",
       "              \n",
       "                       [[-9.7802e-02,  1.3497e-02,  3.7561e-02],\n",
       "                        [-1.9340e-02, -4.1947e-02, -6.3926e-04],\n",
       "                        [-8.3725e-02, -6.4184e-02, -2.4040e-03]],\n",
       "              \n",
       "                       [[ 9.3643e-02, -3.2414e-02,  5.2247e-02],\n",
       "                        [-4.1484e-02, -2.8060e-02, -1.0034e-01],\n",
       "                        [ 8.7330e-02,  1.0264e-01, -2.2139e-03]],\n",
       "              \n",
       "                       [[ 6.6974e-02,  8.6219e-02,  5.2359e-02],\n",
       "                        [ 5.4288e-02, -1.0035e-01, -9.9050e-02],\n",
       "                        [-8.0906e-02,  3.2970e-02, -9.1177e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.0464e-02, -5.1092e-02, -9.7154e-02],\n",
       "                        [ 1.4203e-04,  1.5207e-02, -6.1686e-02],\n",
       "                        [ 6.9018e-02, -4.0018e-02, -2.9676e-02]],\n",
       "              \n",
       "                       [[ 8.0309e-02,  9.0499e-02, -1.2093e-02],\n",
       "                        [-7.5671e-02, -5.2881e-02,  1.3423e-02],\n",
       "                        [ 6.1790e-02,  5.2477e-02, -4.6547e-02]],\n",
       "              \n",
       "                       [[-9.9650e-02, -9.2249e-02, -3.3537e-02],\n",
       "                        [ 1.3223e-03, -4.7347e-02, -8.3348e-02],\n",
       "                        [ 1.1109e-02, -8.3668e-02, -8.0946e-02]],\n",
       "              \n",
       "                       [[-8.5692e-02, -2.8563e-02,  9.3104e-02],\n",
       "                        [ 4.1207e-02, -1.2498e-02,  2.1694e-02],\n",
       "                        [ 4.1975e-02,  6.1414e-04, -8.5020e-02]],\n",
       "              \n",
       "                       [[-6.4944e-02, -7.1610e-02, -2.6766e-03],\n",
       "                        [-9.6492e-02, -1.9166e-02, -3.8545e-02],\n",
       "                        [ 1.0345e-01,  8.5679e-02,  6.1227e-02]],\n",
       "              \n",
       "                       [[ 5.9116e-03, -3.4129e-02,  2.6887e-02],\n",
       "                        [-7.2830e-02, -4.4957e-02, -2.1175e-02],\n",
       "                        [-2.4766e-02, -9.9854e-02,  4.1903e-02]],\n",
       "              \n",
       "                       [[ 8.6803e-02, -5.8141e-02,  2.8415e-02],\n",
       "                        [-1.2225e-02, -3.8445e-03,  6.1443e-03],\n",
       "                        [ 9.1346e-02,  1.4124e-02, -6.6690e-02]],\n",
       "              \n",
       "                       [[-3.7917e-02,  5.1495e-02,  3.2893e-02],\n",
       "                        [ 2.0487e-03, -1.3912e-02, -4.1012e-02],\n",
       "                        [-3.7413e-02, -5.5602e-02,  1.7273e-02]],\n",
       "              \n",
       "                       [[ 2.9603e-02,  8.0717e-02, -2.3813e-02],\n",
       "                        [ 7.5461e-03,  6.8125e-02,  4.5852e-02],\n",
       "                        [ 1.3544e-02,  3.2390e-02,  5.4714e-03]],\n",
       "              \n",
       "                       [[-9.0419e-02,  4.0636e-03, -2.3040e-02],\n",
       "                        [ 9.5123e-02,  9.5145e-02,  2.0912e-02],\n",
       "                        [ 9.4215e-02, -5.4288e-02,  9.1619e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.0756e-02, -4.0288e-03, -8.4592e-02],\n",
       "                        [-3.4015e-02, -2.8189e-02,  1.7411e-03],\n",
       "                        [-9.5569e-02,  1.9535e-02, -4.3839e-02]],\n",
       "              \n",
       "                       [[-2.6989e-02, -5.4443e-02, -2.2255e-02],\n",
       "                        [-9.7896e-02, -5.5885e-02,  9.7108e-03],\n",
       "                        [ 6.9072e-02,  9.5790e-02, -7.9737e-02]],\n",
       "              \n",
       "                       [[ 4.4264e-02, -5.9419e-02, -8.1498e-02],\n",
       "                        [-4.6417e-03, -6.0468e-02, -9.0783e-02],\n",
       "                        [-9.8509e-02, -7.0556e-02,  8.6619e-02]],\n",
       "              \n",
       "                       [[ 5.8788e-02, -4.1726e-02, -7.0553e-02],\n",
       "                        [-8.1085e-02, -6.2246e-02, -4.3376e-02],\n",
       "                        [ 6.3308e-02,  3.4496e-02, -4.0622e-02]],\n",
       "              \n",
       "                       [[ 7.2567e-02, -6.5484e-02, -8.5876e-02],\n",
       "                        [ 2.3006e-02, -5.8123e-02,  2.9987e-02],\n",
       "                        [ 8.9306e-02, -4.9849e-02, -7.3556e-02]],\n",
       "              \n",
       "                       [[ 3.9676e-02, -9.5200e-02,  9.4044e-02],\n",
       "                        [-4.9780e-02,  5.0961e-02, -8.3818e-02],\n",
       "                        [-7.1348e-02,  1.1611e-02,  3.7463e-02]],\n",
       "              \n",
       "                       [[ 8.1734e-02,  8.8158e-02, -6.0623e-03],\n",
       "                        [-1.3552e-02,  1.7424e-02, -2.4486e-02],\n",
       "                        [ 3.5882e-03, -9.9828e-02, -8.6531e-02]],\n",
       "              \n",
       "                       [[ 7.2233e-02, -6.1597e-02,  8.3008e-02],\n",
       "                        [ 1.1568e-02,  2.5676e-02,  9.5804e-02],\n",
       "                        [-5.8628e-02, -1.6640e-02,  1.8675e-02]],\n",
       "              \n",
       "                       [[ 3.6012e-02, -1.0259e-01,  3.7464e-02],\n",
       "                        [-6.2163e-02,  1.3846e-02,  7.1315e-02],\n",
       "                        [-1.0500e-02, -3.3346e-03, -7.8757e-03]],\n",
       "              \n",
       "                       [[ 8.7962e-02,  5.9907e-02,  1.7727e-02],\n",
       "                        [-6.3437e-02, -5.7241e-02,  8.3964e-02],\n",
       "                        [ 7.5834e-02,  6.1033e-02, -8.2189e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.2092e-02, -1.0076e-02,  7.7661e-02],\n",
       "                        [ 9.1553e-02,  1.1554e-02, -4.3863e-02],\n",
       "                        [ 9.9153e-02, -5.4931e-02,  6.8876e-02]],\n",
       "              \n",
       "                       [[-1.0108e-01, -3.3153e-02, -9.1902e-02],\n",
       "                        [-4.7284e-02,  4.4759e-02, -7.5529e-02],\n",
       "                        [-9.1158e-02,  7.5371e-02,  5.6270e-02]],\n",
       "              \n",
       "                       [[-1.1527e-03, -7.4309e-02, -2.7927e-02],\n",
       "                        [-3.4129e-02,  6.5100e-02, -3.4478e-02],\n",
       "                        [-3.0360e-02, -7.4720e-02, -4.9646e-02]],\n",
       "              \n",
       "                       [[ 5.7074e-02,  6.7914e-02,  1.5315e-02],\n",
       "                        [-3.9549e-02,  1.0124e-01,  2.0806e-02],\n",
       "                        [-4.0688e-02, -3.6535e-02, -1.4752e-02]],\n",
       "              \n",
       "                       [[ 4.9974e-02,  3.8555e-02,  7.6418e-02],\n",
       "                        [-4.7494e-03,  8.7183e-02, -4.2816e-02],\n",
       "                        [-4.8547e-02, -3.8927e-02, -9.8896e-02]],\n",
       "              \n",
       "                       [[-6.9195e-02, -9.5382e-02, -6.2294e-03],\n",
       "                        [ 9.9374e-04, -2.7358e-02, -7.2035e-02],\n",
       "                        [ 9.5637e-02, -3.4926e-02,  5.0233e-02]],\n",
       "              \n",
       "                       [[ 7.3408e-02, -6.9291e-02, -1.3179e-02],\n",
       "                        [ 6.0923e-02,  1.0218e-01, -1.3299e-02],\n",
       "                        [ 7.6382e-02, -8.2732e-02, -6.8489e-02]],\n",
       "              \n",
       "                       [[ 8.6682e-02, -9.9801e-03,  1.0414e-01],\n",
       "                        [ 7.6651e-03, -4.3714e-02,  1.0011e-01],\n",
       "                        [ 9.2179e-02,  9.7826e-03, -6.3900e-02]],\n",
       "              \n",
       "                       [[-4.5639e-03, -5.0693e-02,  7.6810e-02],\n",
       "                        [ 4.8829e-03,  2.2191e-02,  6.3927e-02],\n",
       "                        [ 3.4916e-02, -6.5803e-02,  8.7566e-02]],\n",
       "              \n",
       "                       [[ 6.4758e-02, -6.5073e-02,  7.9700e-02],\n",
       "                        [ 2.9905e-02, -2.0750e-02, -7.5385e-02],\n",
       "                        [-1.7490e-02, -1.0335e-01,  6.0163e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.6343e-02, -3.0347e-02,  9.7720e-02],\n",
       "                        [-3.9032e-02,  1.8051e-02, -7.3459e-02],\n",
       "                        [-4.4565e-03,  4.2610e-02,  4.5403e-02]],\n",
       "              \n",
       "                       [[-3.5346e-03, -5.3154e-02,  7.3680e-02],\n",
       "                        [ 6.9788e-02,  1.6916e-02, -4.8475e-02],\n",
       "                        [ 2.2349e-02,  2.8186e-04,  9.6302e-02]],\n",
       "              \n",
       "                       [[ 1.5621e-02,  8.1301e-03,  7.2057e-03],\n",
       "                        [ 5.6079e-02, -1.3024e-03,  9.0351e-02],\n",
       "                        [ 5.4917e-02, -7.9650e-02, -1.2063e-06]],\n",
       "              \n",
       "                       [[-8.9472e-02, -8.0934e-02,  2.0480e-02],\n",
       "                        [ 2.3687e-02, -9.2246e-03,  1.0019e-01],\n",
       "                        [-5.6627e-02, -4.4176e-02, -1.6881e-02]],\n",
       "              \n",
       "                       [[ 6.3911e-04, -8.9284e-03,  9.4909e-02],\n",
       "                        [-4.4519e-02, -5.5137e-02,  9.0599e-03],\n",
       "                        [ 7.9171e-02,  2.5019e-02,  5.6787e-02]],\n",
       "              \n",
       "                       [[ 2.0406e-02,  8.9839e-02,  6.3311e-02],\n",
       "                        [ 7.5428e-02, -1.4198e-02, -8.7268e-02],\n",
       "                        [-5.0002e-02,  3.5910e-02,  7.3950e-02]],\n",
       "              \n",
       "                       [[-4.1184e-02,  8.7218e-02,  1.5150e-02],\n",
       "                        [ 4.1869e-04,  4.1093e-03, -1.8623e-02],\n",
       "                        [ 9.8683e-02,  4.5784e-03,  6.4564e-02]],\n",
       "              \n",
       "                       [[-8.8967e-02, -5.4309e-02,  1.1852e-02],\n",
       "                        [ 8.4169e-02,  5.0184e-02,  2.0076e-02],\n",
       "                        [-1.0414e-01,  1.9816e-03, -6.9581e-02]],\n",
       "              \n",
       "                       [[-9.0006e-02,  1.4414e-02, -6.6693e-02],\n",
       "                        [ 9.5674e-02, -5.7294e-02,  3.3970e-02],\n",
       "                        [ 6.1871e-02, -8.1928e-02,  5.3946e-02]],\n",
       "              \n",
       "                       [[-1.4114e-02,  5.4619e-02,  1.0201e-01],\n",
       "                        [-4.4922e-02, -4.5653e-02,  8.3753e-02],\n",
       "                        [ 1.1722e-02, -1.0513e-02,  7.9971e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0928e-02, -5.2047e-03,  7.2403e-02],\n",
       "                        [ 4.1195e-02, -6.8180e-02,  2.7398e-02],\n",
       "                        [-8.0368e-02, -5.7245e-02,  6.7779e-02]],\n",
       "              \n",
       "                       [[-2.8093e-02, -5.3691e-02,  7.4717e-03],\n",
       "                        [ 2.5759e-02, -6.5524e-02, -7.1084e-02],\n",
       "                        [-1.0209e-01,  2.7236e-02, -6.8013e-02]],\n",
       "              \n",
       "                       [[ 8.0331e-03, -2.3576e-02, -6.8923e-02],\n",
       "                        [-3.3636e-02, -8.1027e-02, -5.5797e-02],\n",
       "                        [-3.2857e-03, -9.0116e-02, -9.2447e-02]],\n",
       "              \n",
       "                       [[ 7.8958e-02,  9.9188e-03, -4.6618e-02],\n",
       "                        [-3.5047e-03,  7.8168e-02, -8.7939e-02],\n",
       "                        [-5.5886e-02, -7.6226e-02, -7.6634e-03]],\n",
       "              \n",
       "                       [[-3.6274e-03, -8.2146e-02,  7.3163e-02],\n",
       "                        [-8.0946e-02,  9.8414e-02, -7.2560e-02],\n",
       "                        [-1.4446e-02,  1.9710e-02, -4.6852e-02]],\n",
       "              \n",
       "                       [[ 9.6939e-02, -7.2673e-02, -5.8427e-03],\n",
       "                        [-7.7398e-02,  2.9261e-02,  8.9871e-02],\n",
       "                        [ 9.7776e-02,  1.2514e-02, -5.2773e-02]],\n",
       "              \n",
       "                       [[ 1.0244e-01,  7.8667e-03,  7.1317e-02],\n",
       "                        [-5.4751e-02, -4.8920e-02, -8.7504e-02],\n",
       "                        [ 9.6990e-02,  1.7486e-02, -7.5704e-02]],\n",
       "              \n",
       "                       [[ 9.0535e-03, -4.5211e-02,  5.2659e-03],\n",
       "                        [ 3.4988e-02, -5.2308e-02,  1.8394e-02],\n",
       "                        [-6.6553e-02,  2.0312e-02, -1.0178e-01]],\n",
       "              \n",
       "                       [[ 1.6797e-02,  1.0473e-01,  9.7094e-02],\n",
       "                        [ 3.8451e-02,  7.7563e-02,  1.0248e-01],\n",
       "                        [ 2.9870e-02,  3.5156e-02,  1.3707e-02]],\n",
       "              \n",
       "                       [[ 9.3322e-02,  9.0551e-02, -4.9570e-02],\n",
       "                        [-4.3333e-03, -5.3110e-02,  3.7824e-02],\n",
       "                        [-1.0214e-01,  3.7301e-02, -2.8929e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8227e-02,  3.2899e-02, -5.2454e-02],\n",
       "                        [ 5.4687e-02,  4.4762e-02, -8.9602e-02],\n",
       "                        [ 1.0517e-01,  9.0731e-02,  6.5584e-02]],\n",
       "              \n",
       "                       [[-1.0699e-02,  3.7345e-02, -5.7028e-02],\n",
       "                        [-3.5818e-02,  4.9749e-02,  4.6925e-02],\n",
       "                        [ 4.1741e-02, -1.0053e-01,  8.7350e-02]],\n",
       "              \n",
       "                       [[-4.4028e-02,  9.1223e-02,  8.6852e-02],\n",
       "                        [ 3.9070e-02,  1.0502e-01,  6.0528e-02],\n",
       "                        [ 6.1821e-02, -3.5794e-02,  9.7766e-02]],\n",
       "              \n",
       "                       [[ 2.7627e-02,  6.2280e-02, -2.3834e-02],\n",
       "                        [ 7.6340e-02,  9.3509e-02, -8.0770e-02],\n",
       "                        [ 8.6415e-02, -6.9664e-02, -7.2571e-02]],\n",
       "              \n",
       "                       [[-8.8089e-02,  3.0459e-02, -7.9144e-02],\n",
       "                        [-3.9680e-02, -5.2988e-02,  2.8172e-02],\n",
       "                        [-1.0349e-01, -4.8324e-02,  7.7112e-04]],\n",
       "              \n",
       "                       [[ 9.4660e-03, -4.7605e-02,  3.7764e-02],\n",
       "                        [-6.9544e-02, -8.9270e-02, -1.4986e-02],\n",
       "                        [-5.6989e-02,  6.6443e-02, -7.2049e-02]],\n",
       "              \n",
       "                       [[-8.8494e-03,  4.3782e-02, -9.2311e-02],\n",
       "                        [ 8.1599e-02, -4.7895e-02, -2.8684e-02],\n",
       "                        [-6.4480e-02, -3.9279e-02, -4.0645e-02]],\n",
       "              \n",
       "                       [[-9.3801e-02,  3.6019e-02, -3.3768e-04],\n",
       "                        [ 1.0311e-01,  7.1117e-02,  9.1699e-02],\n",
       "                        [ 3.1014e-02,  5.5388e-02,  9.8704e-02]],\n",
       "              \n",
       "                       [[ 8.6545e-02, -8.0996e-02, -2.3636e-02],\n",
       "                        [-1.0166e-01,  3.9877e-03, -3.7229e-02],\n",
       "                        [ 9.1486e-02,  1.6666e-02,  1.1601e-03]],\n",
       "              \n",
       "                       [[-7.6248e-02, -8.2718e-02,  1.6594e-02],\n",
       "                        [-5.2376e-02, -4.8409e-02,  7.3938e-02],\n",
       "                        [-5.4952e-02, -4.6918e-02,  8.0934e-02]]]], device='mps:0')),\n",
       "             ('conv_block_2.2.bias',\n",
       "              tensor([ 0.0412, -0.0599,  0.0319,  0.0531, -0.0936,  0.0197,  0.0241, -0.0041,\n",
       "                       0.1011, -0.0697], device='mps:0')),\n",
       "             ('classifier.1.weight',\n",
       "              tensor([[ 0.0245, -0.0240, -0.0387,  ...,  0.0094, -0.0015, -0.0225],\n",
       "                      [ 0.0228,  0.0067, -0.0439,  ..., -0.0302,  0.0368,  0.0293],\n",
       "                      [ 0.0303,  0.0347, -0.0211,  ...,  0.0207, -0.0423, -0.0240],\n",
       "                      ...,\n",
       "                      [-0.0359, -0.0343,  0.0166,  ...,  0.0324,  0.0113, -0.0143],\n",
       "                      [-0.0294, -0.0316,  0.0251,  ..., -0.0056,  0.0300, -0.0396],\n",
       "                      [-0.0246, -0.0035, -0.0046,  ..., -0.0146, -0.0358,  0.0175]],\n",
       "                     device='mps:0')),\n",
       "             ('classifier.1.bias',\n",
       "              tensor([ 0.0320, -0.0445,  0.0246, -0.0357, -0.0442,  0.0156, -0.0010, -0.0277,\n",
       "                       0.0404,  0.0037], device='mps:0'))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup loss function, optimizer and evaluation fuction\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.1)\n",
    "model_2.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Training and testing `model_2` using our training and testing loop functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "------\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "Train loss: 0.59093 | Train acc: 78.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:06<00:12,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3934 | Test acc: 85.64%\n",
      "Epoch: 1\n",
      "------\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "Train loss: 0.36547 | Train acc: 86.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:12<00:06,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3546 | Test acc: 86.92%\n",
      "Epoch: 2\n",
      "------\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "Train loss: 0.32907 | Train acc: 88.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:18<00:00,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3292 | Test acc: 87.82%\n",
      "Train time on mps: 18.299 in seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "train_time_start_model_2 = timer()\n",
    "\n",
    "#Train and test model\n",
    "epochs = 3\n",
    "for epoch in trange(epochs):\n",
    "    print(f\"Epoch: {epoch}\\n------\")\n",
    "    train_step(model=model_2,\n",
    "               data_loader=train_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               device=device)\n",
    "    test_step(model=model_2,\n",
    "              data_loader=test_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              device=device)\n",
    "    \n",
    "train_time_end_model_2 = timer()\n",
    "total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
    "                                            end=train_time_end_model_2,\n",
    "                                            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 607.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV2',\n",
       " 'model_loss': 0.3291807472705841,\n",
       " 'model_acc': 87.81948881789137}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model_2 results\n",
    "model_2_results = eval_model(model_2,\n",
    "                             data_loader=test_dataloader,\n",
    "                             loss_fn=loss_fn,\n",
    "                             accuracy_fn=accuracy_fn, \n",
    "                             device=device)\n",
    "\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FashionMNISTModel0</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>83.426518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FashionMNISTModelV1</td>\n",
       "      <td>0.690066</td>\n",
       "      <td>74.810304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNISTModelV2</td>\n",
       "      <td>0.329181</td>\n",
       "      <td>87.819489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  model_loss  model_acc\n",
       "0   FashionMNISTModel0    0.476639  83.426518\n",
       "1  FashionMNISTModelV1    0.690066  74.810304\n",
       "2  FashionMNISTModelV2    0.329181  87.819489"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 8. Compare model results and training time\n",
    "compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
